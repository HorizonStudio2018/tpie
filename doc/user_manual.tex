%%
%% $Id: user_manual.tex,v 1.14 1999-07-06 22:13:03 large Exp $
%%
\chapter{Overview}

The data sets involved in many modern applications are often too massive to
fit in main memory of even the most powerful computers and must therefore
reside on disk. Thus communication between internal and external memory,
and not actual computation time, becomes the bottleneck in the
computation. This is due to the huge difference in access time of fast
internal memory and slower external memory such as disks. While typical
access time of main memory is measured in nanoseconds, a typical access
time of a disk is on the order of milliseconds~\cite{cockcroft:sun}. So
roughly speaking there is a factor of a million in difference in the access
time of internal and external memory. A good example of an applications
involving massive amounts of geometric data is NASAs Earth Observation
System (EOS)~\cite{cromp,kobler:nasa}, which is expected to manipulate
petabytes (thousands of terebytes, or million of gigabytes) of data.

The goal of theoretical work in the area of {\em external memory
algorithms\/} (also called {\em I/O algorithms\/} or {\em out-of-core
algorithms}) is to develop algorithms that minimize the input/output
communication (or just {\em I/O}) performed when solving a given
problem. The area was effectively started in the late eighties by Aggarwal
and Vitter~\cite{aggarwal:input} and subsequently I/O algorithms have been
developed for several problem domain, including computational
geometry~\cite{goodrich:external,arge:buffer,arge:theory,arge:gis,aamvv-empgbtag97,arge:interval,kanellakis:indexing,ramaswamy:path,subramanian:p-range,vengroff:efficient,agarwal:efficient,zhu:further,agarwal:point,arge:scalable,arge:theory,callahan:topology,franciosa:orders,grossi:cross-tree,zhu:further},
\index{computational geometry} graph
algorithms~\cite{chiang:external,arge:buffer,kumar:improved,abello:functional,crauser:randomized,arge:obdd,feuerstein:memory,nodine:blocking,ullman:input},
\index{graph algorithms} and string
processing~\cite{ferragina:fully,ferragina:fast,arge:strings,crauser:construction}.
Also I/O performance can often be improved if many disks can efficiently be
used in parallel and the use of parallel disks\index{parallel disks}
\index{disks!parallel|see{parallel disks}} has received a lot of
theoretical attention.\comment{LA: Add refs.} Recent surveys of theoretical
results in the area of I/O-efficient algorithms can be found
in~\cite{arge:gisbook,arge:thesis,vitter:podssurvey,vitter:extdatassurvey}

%As of today, gigabyte computer systems exist on desktops, and terabyte
%systems are not unheard of.  In the not too distant future, systems
%designed to manage petabytes of information will come on-line.  The most
%important characteristic of such vast amounts of data is that they cannot
%possibly be stored in the primary memories of even the most powerful
%computers. Instead, they must be stored on secondary memory, such as
%magnetic disks, or tertiary memory, such as tapes and optical memory.
%Compared to CPUs and solid state random access memory, these devices are
%extraordinarily slow; the difference in access time is typically 2 to 5
%orders of magnitude. Because of the low speed of secondary storage, good
%performance in the Input/Output (I/O) system that links secondary storage
%to main memory and the CPU or CPUs is critical if good performance is to be
%achieved overall. Performance can be further improved if many disks can be
%efficiently used in parallel. Unfortunately, existing I/O systems generally
%do not perform adequately~\cite{patt:computer}.

%Recently, a number of parallel I/O systems have become
%available, though in most cases they have failed to take adequate advantage
%of the insights theorists have had to offer \cite{cormen:integrate-tr}.

TPIE, a transparent parallel I/O environment, is designed to bridge the gap
between the theory and practice of parallel I/O systems. It is intended to
demonstrate how all of the following can be obtained simultaneously:

\begin{itemize}
\item Abstract away the details of how I/O is performed so that programmers
need only deal with a simple high level interface.
\item Implement I/O-optimal paradigms for large scale computation that are
efficient not only in theory, but also in practice.
\item Remain flexible, allowing programmers to specify the functional
details of computation taking place within the supported paradigms.  This
will allow a wide variety of algorithms to be implemented within the
system.
\item Be portable across a variety hardware platforms.
\item Be extensible, so that new features can be easily added later.
\end{itemize}

TPIE is implemented as a set of templated classes and functions in
C++.\index{C++} It also includes a small library and a set of test and
sample applications. 

\section{Hardware Platforms}
\index{hardware platforms}

TPIE has been tested on a variety of hardware platforms with a variety of
flavors of UNIX operating systems. Combinations that have been tested
include:
\begin{itemize}
\item Sun Sparc/Solaris 5.x
\item DEC Alpha/Digital Unix 4.0
\item DEC Alpha/FreeBSD 4.0
\item Intel Pentium/FreeBSD 4.0
\item Intel Pentium/Solaris 5.x
\end{itemize}


\section{Future releases}
\index{Future releases}
\index{Releases!future|see{future releases}}

The current release of TPIE (\version) include the fundamental routines for
solving fundamental {\em batched} problems such as sorting. These routines
enables the programmer to write efficient and portable implementations of
algorithms that makes use of the fundamental {\em streaming} primitives
which has been identified in theoretical
work~\cite{arge:gisbook,vitter:podssurvey}. Relative to version 0.8.02a the
current version of TPIE has been updated to improved performance and a
number of bugs has been fixed. This manual has been updated to reflect
these changes and several chapters has been expanded in order to allow the
TPIE programmer to tune the systems for maximal performance on a give
platform. A list of the major changes can be found on the TPIE www page at
\verb|http://www.cs.duke.edu/TPIE/|. Keep in mind that the TPIE project is
work in progress -- several major planned components has not yet been
implemented and work is also being done to update and extend the current
manual. Users of TPIE are encouraged to send bug reports, ect., to
\verb|tpie@cs.duke.edu|.

Work on extending and/or improving TPIE is currently underway or in
progress. Projects include further performance improvements, support for
parallel disks, addition of the distribution sweeping
primitive~\cite{goodrich:external}, and addition of several application
examples (examples of applications written using TPIE can be found in the
papers listed on the TPIE home page). Another major project involved the
addition of support for random access to blocks as opposed to the stream
oriented access used in the current version of TPIE. This addition will
facilitate the implementation of indexing structures (external data
structures). Users interested in obtaining/testing preliminary versions of
these extensions are encouraged to send a request to
\verb|tpie@cs.duke.edu|.


\chapter{Obtaining and Installing TPIE}

\section{Licensing}

TPIE is available under the terms of the GNU General Public License,
\index{license} version 2.  A copy of this license appears in
Appendix~\ref{app:gpl}.

\section{Where to get TPIE}

The latest version of TPIE, \version, is an alpha test version.  It is
available through the \htmladdnormallink{TPIE WWW Home Page}{%
\begin{rawhtml}
http://www.cs.duke.edu/TPIE/
\end{rawhtml}%
}%
\begin{latexonly}
at URL \verb|http://www.cs.duke.edu/TPIE/|.
\end{latexonly}
To obtain the TPIE source distribution\index{source distribution}, follow
the pointers from the home page to the distribution itself, which consists
of a gzipped tar file named {\tt tpie-\version.tgz}. Your Web browser
should be capable of downloading this file to your local machine.


\section{Prerequisites}
\index{GNU software}
\label{sec:gnu-software}

To uncompress and unarchive the distribution, you will need either the GNU
\verb|tar| utility, or \verb|gzip| and a \verb|tar| program. (the GNU
version can decompress and untar at the same time with the '\verb|z|'
option). The GNU \verb|make| utility is also needed. This utility is
usually located in \verb|/usr/local/bin/make| (or is called
\verb|gmake|).
% \verb|LaTeX| and associated tools are needed to generate the
%manual, and \verb|latex2html| is required to generate the HTML version of
%the manual.

TPIE is heavily dependent on the compiler used, mainly because of the use
of C++ templates. It currently requires the GNU C++ compiler, \verb|gcc|,
version~\gxxversion~(it has also been successfully compiled with \verb|gcc|
version 2.7.2.1 on some systems). We expect that it will also be compatible
with future version of this compiler. TPIE has also been successfully
compiled using \verb|egcs|, version 2.91.66.

%In general, invoking the above utilities with the single command line
%argument \verb|--version| will indicate whether they are compatible.
Information on where and how to obtain and install GUN software is
available at URL {\tt http://www.gnu.org/software/software.html}.


\section{Installation}
\index{installation}

Once you have obtained the TPIE source distribution file
{\tt tpie-\version.tgz}, you must decide where to install it.
\verb|/usr/local/tpie/| is a typical place.

Place {\tt tpie-\version.tgz} in the directory in which TPIE is to
be installed, \verb|cd| into that directory, and execute the command

\begin{flushleft}
{\tt tar xzf tpie-\version.tgz}
(or {\tt gunzip -c tpie-\version.tgz | tar xvf -} )  
\end{flushleft}

This will produce a directory {\tt tpie-\version} with subdirectories
\verb|include|, \verb|lib|, \verb|test|, and \verb|doc|.  Enter the
directory {\tt tpie-\version}.  You must now configure TPIE for your
particular system.  To do this, use the command

\begin{verbatim}
./configure
\end{verbatim}

\index{configuration}The configuration program will take some time to
examine the parameters of your system.  Once it has done so, it will
produce the various Makefiles and configuration files required to
build TPIE on your system.  When this is done, simply invoke your version
of GNU \verb|make|:

\begin{verbatim}
make all
\end{verbatim}

to build the complete TPIE system.  This will build the following
components:

\begin{description}
\item[\verb|include|] The TPIE header files.\index{header files}
\item[\verb|lib|] The TPIE library.  This is relatively small, as most
  of the TPIE system remains in the form of templated header
  files.\index{library}
\item[\verb|test|] A series of test applications designed to verify
  that TPIE is operating correctly.  This directory also includes the
  code to the example applications described in
  Chapter~\ref{ch:examples}.\index{test applications}
\item[\verb|doc|] Complete documentation for TPIE, consisting of the
  document you are reading right now in various formats: HTML, and DVI and
  Postscript(TM) for printing.\index{documentation}
\end{description}





\section{Customization}
\index{Customization}

\comment{LA: We need to change this when we change logging}
It is possible to customize the installation by providing arguments to
the {\tt configure} script.\index{configuration:options} None of these
arguments are necessary and the first time you build TPIE you should
probably not need any of them. The arguments recognized are as
follows:
\begin{description}
\item[\verb|--enable-log-lib|] 
  \index{enable-log-lib@{\tt --enable-log-lib}}
  Enable logging in TPIE library code.
  This can also be accomplished at compile time by defining the macro
  \verb|TP_LOG_LIB| using the syntax \verb|make lib TP_LOG_LIB=1|.
  This is useful for debugging the TPIE library, but slows it down.
  This option works by defining \verb|TPL_LOGGING|
  \index{TPL_LOGGING@{\tt TPL\_LOGGING}}
  when compiling the library. 
  Section \ref{sec:logging} discusses TPIE logging.
\item[\verb|--enable-assert-lib|]  
  \index{enable-assert-lib@{\tt --enable-assert-lib}}
  Enable assertions in the TPIE library code for debugging purposes.
  This can also be accomplished at compile time by defining the macro
  \verb|TP_ASSERT_LIB| using the syntax \verb|make lib TP_ASSERT_LIB=1|.
  This option works by defining \verb|DEBUG_ASSERTIONS|
  \index{DEBUG_ASSERTIONS@{\tt DEBUG\_ASSERTIONS}} 
  when compiling the library.
\item[\verb|--enable-log-apps|]  and
\item[\verb|--enable-assert-apps|]  
  \index{enable-assert-apps@{\tt --enable-assert-apps}}
  \index{enable-log-apps@{\tt --enable-log-apps}}
  Similar to {\tt --enable-log-lib} and {\tt --enable-assert-lib}, but
  they apply to the test application code.  Running \verb|make test|
  with the options \verb|TP_LOG_APPS=1| and/or \verb|TP_ASSERT_APPS=1|
  accomplishes the same thing.
\item[\verb|--enable-expand-ami-scan|]  Expand the macros in the file
  \verb|ami_scan.h| when making the include directory with the
command {\tt make include} (or {\tt make all}).  This is mainly useful for
debugging the code in \verb|ami_scan.h| itself, and is not normally
needed by TPIE programmers.  It may make compilation of TPIE programs
slightly faster because the macro processor of the C++ compiler will
have less work to do.  In addition to the standard GNU tools mentioned
in Section~\ref{sec:gnu-software}, this requires \verb|perl|.
\item[\verb|--disable-*|]  Any of the options above can be explicitly
  disabled  by using this syntax.  For example
  \verb|--disable-expand-ami-scan|. 
\end{description}


\chapter{A Taste of TPIE via a Sample Program}
\label{ch:samplepgmr}

The next chapter is a detailed TPIE tutorial. Here we present a quick look
at TPIE via a simple TPIE program. One of the primary ideas behind TPIE is
to allow a user to view and \emph{specify} I/O efficient computation simply
as a high-level coordination of data movement interspersed with
appropriate internal memory computing, with all low level details of I/O
being ``under the hood''. Accordingly, TPIE provides classes \emph{scan
management objects}, \emph{merge management objects}, etc. that allow the
user to specify sophisticated data movement operations on \emph{streams} of
data in a simple and straightforward manner. The above mentioned
management object classes are built on top of a simple and carefully
designed \emph{stream interface} called \verb|AMI_STREAM|, and the tutorial
in the next chapter explains how to use and specify such management object
classes.

Using the sample example program below, we take a look at TPIE from a
viewpoint at a level just above the \verb|AMI_STREAM| interface.  The
sample program uses simple stream operations to generate a stream of random
integers, scans this stream of integers and partitions them into several
distinct streams. The manner in which I/O operations are handled by TPIE
ensures that the program is I/O efficient.

%Note that a 4-way distribution can easily be specified using an
%appropriately defined scan management object (see
%Section~\ref{sec:scanning}), in which case the user does not have to use
%stream operations.

The most useful aspect of the program is that it gives the user a 
flavor of the sort of things involved in TPIE programming; the typical 
include files, specifying how much memory the program should use, 
streaming operations etc. The program is given in
Section~\ref{sec:samplepgm} and it is discussed in
Section~\ref{sec:samplepgm_discuss}.


\section{Sample Program}\label{sec:samplepgm}
\index{sample program|(}
\index{sample program|)}

The following is the program in {\tt  tpie-\version/doc/sample\_pgm.cpp}.
\begin{verbatim}
#include <iostream.h>
#include <stdlib.h>
#include <sys/time.h>
#include <values.h> //for MAXINT

//Include the file that sets application configuration: It sets what
//kind of BTE (Block Transfer Engine) to use, and where applicable,
//what should be the size of the logical block (the logical block size
//is a user specified multiple of the physical block size) for a
//stream, and so on;
#include "app_config.h"

//Include the file that will allow us to use AMI_STREAMs.
#include <ami.h>

//include wall timer that will allow us to time
#include "wall_timer.h"

//Include TPIE's internal memory sorting routines.
#include <quicksort.h>

//variable which is used to set up TPIE memory accounting
extern int register_new;

//This program writes out an AMI_STREAM of random integers of
//user-specified length, and then, based on 7 partitioning elements
//chosen from that stream, partitions the stream into 8 buckets. Each
//of the buckets is implemented as an AMI_STREAM and the program
//prints the size of each bucket at the end.

//The user needs to specify the length of the initial stream of
//integers and the size of the main memory that can be used.


void
main(int argc, char *argv[]) {
        
        //parse arguments
        if (argc < 3) {
                cout << "Input the number of integers to be generated\n";
                cout << " and the size of memory that can be used\n";
                exit(1);
        }
        int Gen_Stream_Length = atoi(argv[1]);
        long test_mm_size = atol(argv[2]);
        
        //Set the size of memory the application is allowed to use
        MM_manager.resize_heap(test_mm_size);
        //enable TPIE memory accounting
        register_new = 1;
        
        //the source stream of ints
        AMI_STREAM<int> source;

        //the 8 bucket streams of ints
        AMI_STREAM<int> buckets[8];
        
        
        //************************************************************
        //generate the stream of random integers
        AMI_err ae;
        int src_int;
        for (int i = 0; i < Gen_Stream_Length; i++) {
                
                //generate a random int
                src_int = random();
                
                //Now write out the integer into the AMI_STREAM source using 
                //the AMI_STREAM member function write_item()
                if ((ae = source.write_item(src_int)) != AMI_ERROR_NO_ERROR) {
                        cout << "AMI_ERROR " << ae << " during source.write_item()\n";
                        exit(1);
                }
                
        }
        //print stream length
        cout << "source stream is of length " << source.stream_len() << endl;
        
        

        //************************************************************
        //pick the first 7 integers in source stream as partitioning elements
        //(pivots)
        
        //Seek to the beginning of the AMI_STREAM source.
        if ((ae = source.seek(0))!= AMI_ERROR_NO_ERROR) {
                cout << "AMI_ERROR " << ae << " during source.seek()\n";
                exit(1);
        }
        
        //read first 7 integers and fill in the partitioning array
        int partitioning[8];
        int *read_ptr;
        
        for (int i = 0; i < 7; i++) {
                
                //Obtain a pointer to the next integer in AMI_STREAM source
                //using the member function read_item()
                if ((ae = source.read_item(&read_ptr)) != AMI_ERROR_NO_ERROR) {
                        cout << "AMI_ERROR " << ae << " during source.read_item()\n";
                        exit(1);
                }
                
                //Copy the current source integer into the partitioning element array.
                partitioning[i]= *read_ptr;
        }
        cout << "Loaded partitioning array\n";



        //************************************************************
        //sort partitioning array
        
        quicker_sort_op((int *)partitioning,7);
        cout << "sorted partitioning array\n";
        partitioning[7] = MAXINT;



        //************************************************************
        //Partition ints of source into the buckets using partitioning elements
        
        struct timeval tp1, tp2;

        //binary search variables.
        int u,v,l,j;
        
        //start timer
        wall_timer wt;
        wt.start();
        
        //seek to the beginning of the AMI_STREAM source.
        if ((ae = source.seek(0))!= AMI_ERROR_NO_ERROR) {
                cout << "AMI_ERROR " << ae << " during source.seek()\n";
                exit(1);
        }
        
        //scan source stream distributing the integers in the appropriate
        //buckets
        for (int i = 0; i < Gen_Stream_Length; i++) {
                
                //Obtain a pointer to the next integer in AMI_STREAM source
                //using the member function read_item()
                if ((ae = source.read_item(&read_ptr)) != AMI_ERROR_NO_ERROR) {
                        cout << "AMI_ERROR " << ae << " during source.read_item()\n";
                        exit(1);
                }
                v = *read_ptr;

                //find out l such that v is assigned to buckets[l] using binary
                //search
                l = 0;
                u = 7;
                while (u >= l) {
                        j = (l+u)>>1; 
                        if (v < partitioning[j]) {
                                u = j-1;
                        } else {
                                l = j+1;
                        }
                }

                //now write out the int into the AMI_STREAM buckets[l] using 
                //the AMI_STREAM member function write_item().
                if ((ae = buckets[l].write_item(v)) != AMI_ERROR_NO_ERROR) {
                        cout << "AMI_ERROR " << ae << " during buckets[" << l 
                                         << "].write_item()\n";
                        exit(1);
                }
        }
        
        //stop timer
        wt.stop();
        cout << "Time taken to partition is " << wt.seconds() << " seconds" << endl;
        
  //delete the file corresponding to the source stream when source
  //stream gets destructed (this is the default, so this call is not
  //needed)
        source.persist(PERSIST_DELETE);
        
        //let the file correspond to buckets[i] persist on disk when the
        //buckets[i] stream gets destructed
        for (int i = 0; i < 8; i++) {
                buckets[i].persist(PERSIST_PERSISTENT);
                cout << "Length of bucket " << i << " is " 
                                 << buckets[i].stream_len() << endl;
        }
        
}

\end{verbatim}


\section{Discussion of Sample Program}\label{sec:samplepgm_discuss}

In this section we discuss the simple simple C++ sample program in the
previous section. The file \verb|app_config.h| is the TPIE configuration
file. TPIE's \verb|AMI_STREAM| stream I/O operations are carried out under
the hood by one of three possible \emph{block transfer engines
(BTEs)}. Briefly, the \verb|app_config.h| chooses a specific BTE, and the
amount of internal memory used as buffer space for each
\verb|AMI_STREAM|. The \verb|app_config.h| configuration file is further
discussed in Section~\ref{sec:tuning} which also contains a discussion of
how to choose a BTE for a given platform. The file \verb|<ami.h>| contains
TPIEs templated classed and functions, while the file \verb|<quicksort.h>|
contains various quicksort polymorphs. Note that each \verb|AMI_STREAM|
corresponds to an underlying Unix file.

The program illustrates the most fundamental \verb|AMI_STREAM| member
functions \verb|read_item()|, \verb|write_item()|, \verb|seek()| and
\verb|persist()|. Successful execution of these member functions is
indicated by a return value of \verb|AMI_ERROR_NO_ERROR|. The remaining
program is easily understood by means of the comments in the code. The
program distributes a randomly generated source stream of integers into
eight bucket streams, and then displays the time taken by this operation
and the size of each of the eight output buckets. The randomly generated
stream is deleted upon completion of the program
(\verb|source.persist(PERSIST_DELETE)|), while the bucket streams are saved
(made persistent with \verb|buckets[i].persist(PERSIST_PERSISTENT)|) in the
default directory \verb|/var/tmp|. The default location can be changed by
setting the \verb|AMI_SINGLE_DEVICE| variable appropriately (see
Section~\ref{sec:configuration}).

The setting of the \verb|register_new| variable instructs TPIE whether to
run with a user-specified amount of internal memory (\verb|register_new:=
1|) or to run with virtual memory like an ordinary non-TPIE application
would (\verb|register_new:= 0|). In this program, we set
\verb|register_new:= 1| which means that the program will abort if the
allocated internal memory exceeds the specified amount. The call
\verb|MM_manager.resize_heap(test_mm_size)| tells TPIE's internal memory
manager \verb|MM_manager| to disallow the TPIE program's total internal
memory usage (in the ``heap'' area) from exceeding \verb|test_mm_size|
bytes. Note that \verb|test_mm_size| is the second input argument to our
program. When \verb|register_new == 1|, it is the responsibility of the
user to have the \verb|MM_manager| ``resize'' its heap to an appropriate
size as desired. Normally, this amount is the amount of physical main
memory minus the main memory used by the operating system and other
programs running on the machine.

%In the case of the present program, it is desirable to
%ensure that the program is allowed enough memory to comfortably accomodate
%the buffer space required by each one of the nine \verb|AMI_STREAM|s
%involved in the computation. The amount of buffer space required per
%\verb|AMI_STREAM| depends on the BTE implementation chosen in the
%\verb|app_config.h| file. Section~\ref{sec:env-variables} provides details
%of how to determine the buffer-space required for each BTE implementation.


The sample program is compiled by executing the follows:

\begin{verbatim}
g++ sample_pgm.cpp -I../include/ -L../lib/ -ltpie -o sample_pgm
\end{verbatim}

The program can be run with 1000000 random integers and 5000000 bytes of main
memory by execute the following:
\begin{verbatim}
sample_pgm 1000000 5000000
\end{verbatim}


\chapter{Tutorial}
\label{ch:tutorial}

\section{Introduction}

This tutorial is designed to introduce new users to the TPIE system.
It introduces the fundamental paradigms of computation that TPIE
supports, giving source code examples of each.  The majority of the
code presented in the tutorial is available in the test
applications\index{test applications} directory of the distribution, 
{\tt tpie-\version/test/}.

For the sake of brevity, much of the code presented in this tutorial is
incomplete, in the sense that necessary header files \index{header files}
and macros\index{macros} are omitted. Details concerning how to write your
own complete TPIE code is presented at the end of the tutorial in
Section~\ref{sec:compiling} (see also Section~\ref{ch:samplepgmr} and
\ref{sec:choosingbte})\comment{LA: Maybe we should talk shortly about AMI,
BTE, MM somewhere around here - we talk about main memory issues in merging
and compiling sections.}



\section{C++}

If you would like the use TPIE but are not familiar with the C++\index{C++}
language, a number of good books are available. If you are familiar with
C\index{C}, \cite{pohl:c++} is a good place to start. A more basic, but
very comprehensive book is~\cite{deitel:c++}. Once you have mastered the
basics, \cite{meyers:effective} an excellent source of information on
intermediate and advanced C++.  Finally, \cite{ellis:arm} is the definitive
book on C++, though not necessarily the best place for new programmers to
start.

\section{External Memory Algorithms}
\index{External memory algorithms}

Even though you do not need to know any of the theoretical results on
I/O-efficient algorithms to used TPIE, much of what is presented in the
this tutorial (and in general in the manual) will be easilier digestible if
you have some basis knowledge like how a theoretically optimal external
(merge) sort algorithm works. Good reference
are~\cite{aggarwal:input,vitter:podssurvey,arge:gisbook}.


\section{Streams}
\index{stream}\index{structure!of streams}

\comment{LA: Stuff there should maybe be something about: substreams,
persistence, read/write primitives, ect.}

Conceptually, TPIE programs work with streams of data stored in external
memory. A stream is an ordered collection of objects of a particular type.
Various paradigms of computation are defined on these streams, though the
functional details of the computation performed within these paradigms are
left to the TPIE programmer to specify. These details are specified using
an {\emph operation management object},\index{operation management object}
which is an object with member functions designed to work with the
particular paradigm being used.

Creating a stream of objects in TPIE is very much like creating any other
object in C++. The only difference is that data placed in the stream,
whether explicitly, or as is more commonly the case, implicitly, is stored
in external memory (on disk). For example, to create a stream of integers,
we could use either of the following:
\begin{verbatim}
AMI_STREAM<int> stream0;

AMI_STREAM<int> *pstream0 = new AMI_STREAM<int>;
\end{verbatim}

The {\tt AMI} in {\tt AMI\_STREAM} stands for {\emph Access Method
Interface}\index{access method interface}, which is the level of TPIE that
most applications interact with. {\tt AMI\_STREAM} is actually a macro that
evaluates to the name of a particular implementation of streams, but for
now it is safe to assume that it is simply a class.

The {\tt AMI\_STREAM} constructor does not actually put anything into
the stream; it simply creates the necessary data structures to keep
track of the contents of the stream when data is actually put into it.
Data is typically put into streams using \verb|AMI_scan()|, which is
described in the next section.

\section{Scanning}
\label{sec:scanning}

\index{scanning|(} \index{AMI_scan()@{\tt AMI\_scan()}}
The simplest paradigm available in TPIE is scanning.  Scanning can be
used to produce streams, examine the contents of streams, or transform
streams.  

\subsection{Basic Scanning}

The most basic thing a scan can do is write a series of objects to a
stream.  In the following example, we create a stream of integers
consisting of the first 10000 natural numbers.

\begin{verbatim}
class scan_count : AMI_scan_object {
private:
    int maximum;
public:
    int ii;

    scan_count(int max = 1000) : maximum(max), ii(0) {};

    AMI_err initialize(void) 
    {
        ii = 0;
        return AMI_ERROR_NO_ERROR;
    };

    AMI_err operate(int *out1, AMI_SCAN_FLAG *sf)
    {
        *out1 = ++ii;
        return (*sf = (ii <= maximum)) ? AMI_SCAN_CONTINUE : 
            AMI_SCAN_DONE;
    };
};

scan_count sc(10000);
AMI_STREAM<int> amis0;    

void f()
{
    AMI_scan(&sc, &amis0);
}
\end{verbatim}

The class \verb|scan_count| is a class of scan management
object\index{operation management object!scan}.  It has two member
functions, \verb|initialize()| and \verb|operate()|, which TPIE calls
when asked to perform a scan.  The first member function,
\verb|initialize()| is called at the beginning of the scan.  TPIE
expects that a call to this member function will cause the object to
initialize any internal state it may maintain in preparation for
performing a scan.  The second member function, \verb|operate()|, is
called repeatedly during the scan to create objects to go into the
output stream.  \verb|operate()| sets the flag \verb|*sf| to indicate
whether it generated output or not.  Only when \verb|operate()|
returns either an error or \verb|AMI_SCAN_DONE| does TPIE stop calling
it.

The call to \verb|AMI_scan| behaves as the following pseudo-code:

\begin{verbatim} 
AMI_err AMI_scan(scan_count &sc, AMI_STREAM<int> *pamis)
{
    int ii;
    AMI_err ae;    
    AMI_SCAN_FLAG sf;

    sc.initialize();    
    while ((ae = sc.operate(&ii, &sf)) == AMI_SCAN_CONTINUE) {
        if (sf) {
            write ii to *pamis;
        }
    }

    if (ae != AMI_SCAN_DONE) {
        handle error conditions;
    }

    return AMI_ERROR_NO_ERROR;
}
\end{verbatim}

Thus, after the function \verb|f()| in the original example code is
called, the stream \verb|amis0| contains the integers from 1 to 10000
in order.

Now that we have produced a stream, there are a variety of things we
can do with it.  One of the simplest things we can do with a stream of
objects is scan it in order to transform it in some way.  As an
example, suppose we wanted to square every integer in the stream
\verb|amis0|.  We could do so using the following code:

\begin{verbatim}
class scan_square : AMI_scan_object {
public:
    AMI_err initialize(void)
    {
        return AMI_ERROR_NO_ERROR;
    };

    AMI_err operate(const int &in, AMI_SCAN_FLAG *sfin,
                    int *out, AMI_SCAN_FLAG *sfout)
    {
        if (*sfout = *sfin) {
            *out = in * in;
            return AMI_SCAN_CONTINUE;
        } else {
            return AMI_SCAN_DONE;
        }
    };
};

scan_square ss;
AMI_STREAM<int> amis1;    

void g() 
{
    AMI_scan(&amis0, &ss, &amis1);
}
\end{verbatim}

Notice that the call to \verb|AMI_scan()| in \verb|g()| differs from
the one we used in \verb|f()| in that it takes two stream pointers and
a scan management object.  By convention, the stream \verb|amis0| is
an input stream, because it appears before the scan management object
\verb|ss| in the argument list.  By similar convention, \verb|amis1|
is an output stream.  Because the call to \verb|AMI_scan| has one
input stream and one output stream, TPIE expects the \verb|operate()|
member function of \verb|ss| to have one input argument (which is
called \verb|in| in the example above) and one output argument (called
\verb|out| in the example above).  Note that the \verb|operate()|
member function of the class \verb|square_scan| also takes two
pointers to flags, one for input (\verb|sfin|) and one for output
(\verb|sfout|).  \verb|*sfin| is set by TPIE to indicate that there is
more input to be processed.  \verb|*sfout| is set by the scan
management object to indicate when output is generated.
If a scan management object has no polymorph of \verb|operate()| that
takes the appropriate type number of arguments for the invocation of
\verb|AMI_scan()| that uses it then a compile-time error is generated.

A call to \verb|AMI_scan| with one input stream and one output stream
behaves as the following pseudo-code:

\begin{verbatim} 
AMI_err AMI_scan(AMI_STREAM<int> *instream, scan_square &ss, 
        AMI_STREAM<int> *outstream)
{
    int in, out;
    AMI_err ae;    
    AMI_SCAN_FLAG sfin, sfout;

    sc.initialize();

    while (1) {
        {
             read in from *instream;
             sfin = (read succeeded);
        }
        if ((ae = ss.operate(in, &sfin, &out, &sf)) == 
            AMI_SCAN_CONTINUE) {
            if (sfout) {
                write out to *outstream;
            }
            if (ae == AMI_SCAN_DONE) {
                return AMI_ERROR_NO_ERROR;
            }
            if (ae != AMI_SCAN_CONTINUE) {
                handle error conditions;
            }
        }
    }
}
\end{verbatim}

More complicated invocations of \verb|AMI_scan()| can operate on up
to four input streams and four output streams.  Here is an example
that takes two input streams of values, \verb|x| and \verb|y|, and
produces four output streams, 
one consisting of the running sum of the
\verb|x| values,
one consisting of the running sum of the
\verb|y| values,
one consisting of the running sum of the
squares of the \verb|x| values,
and
one consisting of the running sum of the
squares of the \verb|y| values.

\begin{verbatim}
class scan_sum : AMI_scan_object {
private:
    double sumx, sumx2, sumy, sumy2;
public:
    AMI_err initialize(void)
    {
        sumx = sumy = sumx2 = sumy2 = 0.0;
        return AMI_ERROR_NO_ERROR;
    };

    AMI_err operate(const double &x, const double &y, 
                    AMI_SCAN_FLAG *sfin,
                    double *sx, double *sy, 
                    double *sx2, double *sy2, 
                    AMI_SCAN_FLAG *sfout)
    {
        if (sfout[0] = sfout[2] = sfin[0]) {
            *sx = (sumx += x);
            *sx2 = (sumx2 += x * x);
        }
        if (sfout[1] = sfout[3] = sfin[1]) {
            *sy = (sumx += y);
            *sy2 = (sumy2 += y * y);
        }        
        return (sfin[0] || sfin[1]) ? AMI_SCAN_CONTINUE : AMI_SCAN_DONE;
    };
};

AMI_STREAM<double> xstream, ystream;

AMI_STREAM<double> sum_xstream, sum_ystream, sum_x2stream, sum_y2stream;

scan_sum ss;

void h()
{
    AMI_scan(&xstream, &ystream, &ss, 
             &sum_xstream, &sum_ystream, &sum_x2stream, &sum_y2stream);
}
\end{verbatim}


\subsection{ASCII Input/Output} \label{sec:ascii-io}

\index{ASCII I/O|see{scanning, ASCII I/O}}
\index{scanning!ASCII I/O|(}
TPIE provides a number of predefined scan management objects.  Among
the most useful are instances of the template classes
\verb|cxx_ostream_scan<T>| and \verb|cxx_ostream_scan<T>|, which are
used for reading ASCII data into streams and writing the contents of
streams in ASCII respectively.  This is done in conjunction with the
\verb|iostream| facilities provided in the standard C++ library.  Any
class \verb|T| for which the operators \verb|ostream
&operator<<(ostream &s, T &t)| and \verb|istream &operator>>(T &t)|
are defined can be used with this mechanism.

As an example, suppose we have a file called \verb|input_nums.txt|
containing one integer per line, such as

\begin{verbatim}
17
289
4195835
3145727
.
.
.
\end{verbatim}

To read this file into a TPIE stream of integers, square each, and
write them out to the file \verb|output_nums.txt| we could use the
following code:

\begin{verbatim}
void f()
{
    ifstream in_ascii("input_nums.txt");
    ofstream out_ascii("output_nums.txt");
    cxx_istream_scan<int> in_scan(in_ascii);
    cxx_ostream_scan<int> out_scan(out_ascii);
    AMI_STREAM<int> in_ami, out_ami;
    scan_square ss;    

    // Read them.
    AMI_scan(&in_scan, &in_ami);

    // Square them.
    AMI_scan(&in_ami, &ss, &out_scan);
    
    // Write them.
    AMI_scan(&out_ami, out_scan);

}    
\end{verbatim}

In order to read from an input file using the scan object
\verb|in_scan|, \verb|AMI_scan()| repeatedly calls
\verb|in_scan->operate()|, just as it would for any scan object.  Each
time \verb|in_scan->operate()| is called, it uses the \verb|>>|
operator to read a single integer from the input file.  When the input
file is exhausted, \verb|in_scan->operate()| returns
\verb|AMI_SCAN_DONE|, and \verb|AMI_scan()| returns to its caller.
The behavior of \verb|out_scan| is similar to that of \verb|in_scan|,
except that it writes to a file instead of reading from one.
\index{scanning!ASCII I/O|)}

\subsection{Multi-Type Scanning}

\index{scanning!multi-type|(}

In all of the examples presented up to this point, scanning has been
done on streams of objects that are all of the same type.
\verb|AMI_scan()| is not limited to such scans, however.  In the
following example, we have a scan management class that takes two
streams of \verb|double|s and returns a stream of complex numbers.

\begin{verbatim}
class complex {
public:
    complex(double real_part, imaginary_part);
    ...
};

class scan_build_complex : AMI_scan_object {
public:
    AMI_err initialize(void) {};
    AMI_err operate(const double &r, const double &i, 
                    AMI_SCAN_FLAG *sfin,
                    complex *out, AMI_SCAN_FLAG *sfout)
    {
        if (*sfout = (sfin[0] || sfin[1])) {
            *out = complex((sfin[0] ? r : 0.0), (sfin[1] ? i : 0.0));
            return AMI_SCAN_CONTINUE;
        } else {
            return AMI_SCAN_DONE;
        }   
    };
};
\end{verbatim}
\index{scanning!multi-type|)}

\subsection{Out of Step Scanning}
\label{sec:out-of-step}

\index{scanning!out of step|(}
In all the examples up to this point, every call to the
\verb|operate()| member function of a scan management object has been
called with each object in the input stream(s) exactly once.  In this
section, we introduce the concept of out of step scanning, which
allows a scan management object to reject certain inputs and ask that
they be resubmitted in subsequent calls to the \verb|operate()| member
function.

Suppose we have two streams of integers, each of which we know is
sorted in ascending order.  We would like to merge the two streams
into a single output stream consisting of all the integers in the two
input streams, in sorted order.  In order to do this with a scan, we
must have the ability to look at the next integer from each stream,
choose the smaller of the two and write it to the output stream, and
then ask for the next number from the stream from which it was taken.
Luckily, there is a simple mechanism for doing this.  The same flags
that TPIE uses to tell the scan management object which inputs are
available can be used by the scan management object to indicate which
inputs were used and which should be presented again.

Consider the following example of a scan management object class which
performs exactly the sort of binary
merge\index{merge!binary}\index{merge sort!binary} described in the
preceding paragraph:

\begin{verbatim}
class scan_binary_merge : AMI_scan_object {
public:
    AMI_err initialize(void) {};
    
    AMI_err operate(const int &in0, const int &in1, AMI_SCAN_FLAG *sfin,
                    int *out, AMI_SCAN_FLAG *sfout) 
    {
        if (sfin[0] && sfin[1]) {
            if (in0 < in1) {
                sfin[1] = false;
                *out = in0;
            } else {
                sfin[0] = false;
                *out = in1;
            }
        } else if (!sfin[0]) {
            if (!sfin[1]) {
                *sfout = false;
                return AMI_SCAN_DONE;
            } else {
                *out = in1;
            }
        } else {
            *out = in0;
        }
        *sfout = 1;
        return AMI_SCAN_CONTINUE;
    }
};
\end{verbatim}

In the operate method, we first check that both inputs are valid by
looking at the flags pointed to by \verb|sfin|.  If both are valid,
then we select the smaller of the inputs and copy it to the output.
We then clear the other input flag to let TPIE know that we did not
use that input, but we will need it later and it should be resubmitted
on the next call to operate. The remainder of the function handles
the cases when one of more of the input streams are empty.
\index{scanning!out of step|)}
\index{scanning|)}


\section{Merging} \label{sec:merging}
\index{merging|(}

While \verb|AMI_scan()| is limited to operate on up to four input and four
output streams, theoretically efficient external memory algorithms often
operates on more than eight streams. An especially common operation is
merging of a large number of input streams into one output
stream.\footnote{Note that ``merge'' here means the process of reading the
content of a number of input streams in some interleaved order producing an
output stream. Merging a number of sorted input streams into a sorted
output stream is a (very common) special case of merging.} An example of
the this is external merge sorting. The binary merging scan management
object presented in the previous section could be used recursively to
implement a merge sorting\index{merge sorting!binary} algorithm. We could
simply divide the input stream into sub-streams small enough to fit into
main memory, read each sub-stream into memory and sort it, and then merge
pairs of streams, then pairs of merged pairs of streams, and so on, until
we had merged all the input back into one completely sorted stream. While
this approach would correctly sort the input, it would not be nearly as
efficient as possible on most machines. The reason is that we typically
have enough main memory available to merge many streams together at one
time~\cite{aggarwal:input}.

TPIE provide the function \verb|AMI_merge()| which, provide that enough
main memory is available, merge a number of input streams into an output
stream in one scan of the input streams. As in the case of \verb|AMI_scan|,
the functional details in how the merge is performed is specified via an
operation management object\index{operation management object } (a merge
management object) with member functions \verb|initialize()| and
\verb|operate()|.\comment{LA: The AMI\_merge stuff should be rewritten with
some examples}\footnote{The merging function also have three other more
specialized polymorphs for merging according to some total order defined by
the used. These polymorphs do not need a merge management object. Refer to
Section~\ref{sec:ref-ami-merge}.} However, often, as in the merge sort
example, one wants to merge more streams than memory constraints dictates
and the merge has to be done in several recursive stages.\comment{LA: Here
we start talking about memory constraints - there should be a general intro
to blocks and stuff somewhere.} In many cases the streams are produced my
dividing a single input stream like in merge sort. Since it can be
cumbersome to compute precisely how many streams can be merged in one pass
--- one must keep track of the space needed for input blocks form each of
the streams being merged, as well as the overhead of any data structures
needed for the merge --- TPIE also provides a mechanism that does most of
the above work for us. The function \verb|AMI_partition_and_merge()|
divides an input stream into sub-streams just small enough to fit into main
memory, operates on each in main memory, then merges them back into a
single output stream, using intermediate streams if memory constraints
dictate. Like in the case if \verb|AMI_merge()|, the functional details of
\verb|AMI_partition_and_merge()| are specified via a merge management
object. In fact the merge management object for \verb|AMI_merge()| is a
special case of the one for \verb|AMI_partition_and_merge()|. The following
example shows such an object:

\begin{verbatim}
class my_merger : AMI_merge_base {
public:
    AMI_err initialize(arity_t arity, const T * const *in,
                       AMI_merge_flag *taken_flags,
                       int &taken_index);
    AMI_err operate(const T * const *in, AMI_merge_flag *taken_flags,
                    int &taken_index, T *out);
    AMI_err main_mem_operate(T* mm_stream, size_t len);
    size_t space_usage_overhead(void);
    size_t space_usage_per_stream(void);
};

AMI_STREAM<T> instream, outstream;

void f() 
{
    my_merger mm;    
    AMI_partition_and_merge(&instream, &outstream, &mm);
}
\end{verbatim}

The class members are as follows:

\begin{description}
\item[\verb|initialize()|] Tells the object how many streams it should
  merge (\verb|arity|) and what the first item from each stream is
  (\verb|in|). \verb|taken_flags| and \verb|taken_index| provide two
  mechanisms for the merge manager to tell TPIE what objects it took
  from the input streams. These are discussed in more detail in 
  the context of a merge sorting example in Section~\ref{sec:mergesort}.
\item[\verb|operate()|]
Just as in scanning, this member function is called repeatedly to process
input objects.
\item[\verb|main\_mem\_operate()|]
Called by TPIE to operate on an array of data in main memory.
\item[\verb|space\_usage\_overhead()|]
Called by TPIE prior to initialization to asses how much main memory this
object will use.
\item[\verb|space\_usage\_per\_item()|]
Called by TPIE prior to initialization to asses how much main memory may be
used per input stream. Merge management objects are allowed to use main
memory space linear in the number of input streams.
\end{description}

\verb|AMI_partition_and_merge()| behaves as indicated by the following
pseudo-code. Note that for simplicity of presentation, boundary conditions are not covered.

\begin{verbatim}
AMI_err AMI_partition_and_merge(instream, outstream, mm)
{
    max_ss = max # of items that can fit in main memory;
    partition instream into num_substreams substreams of size max_ss;

    foreach substream[i] {
        read substream[i] into main memory;
        mm->main_mem_operate(substream[i]);
        write substream[i];
    }

    call mm->space_usage_overhead() and mm->space_usage_per_stream;
    
    compute merge_arity; // Maximum # of streams we can merge.     

    while (num_substreams > 1) {
        for (i = 0; i < num_substreams; i += merge_arity) {
            merge substream[i] .. substream[i+merge_arity-1];
        }
        num_substreams /= merge_arity;
        max_ss *= merge_arity;
    }

    write single remaining substream to outstream;
        
    return AMI_ERROR_NO_ERROR;
}
\end{verbatim}


\subsection{Implementing Mergesort: An Extended Example}
\label{sec:mergesort}

In the following we give example of the implementation and use of a merge
management object for merge sorting integers. First, we declare the class:

\comment{LA: We should probably change AMI\_merge\_base to AMI\_merge\_object at some point}

\begin{verbatim}
class s_merge_manager : public AMI_merge_base<int> { 
private:
    arity_t input_arity;
    pqueue *pq;
public:
    s_merge_manager(void);
    virtual ~s_merge_manager(void);
    AMI_err initialize(arity_t arity, const int * const *in,
                       AMI_merge_flag *taken_flags, int &taken_index);
    AMI_err operate(const int * const *in, AMI_merge_flag *taken_flags,
                    int &taken_index, int *out);
    AMI_err main_mem_operate(int* mm_stream, size_t len);
    size_t space_usage_overhead(void);
    size_t space_usage_per_stream(void);
};
\end{verbatim}

In addition to the standard class members for a merge management
object, we have the following:

\begin{description}
\item[\verb|input\_arity|]
The number of input streams the merge management object must handle.
\item[\verb|pq|]
A priority queue into which items will be placed.
\item[\verb|s\_merge\_manger()|]
A constructor.
\item[\verb|\~{}s\_merge\_manger()|]
A destructor.
\end{description}

Construction and destruction are fairly straightforward.  At construction
time, we have no priority queue because we do not yet know how big the
priority queue should be.  \verb|pq| will be set up when \verb|initialize|
is called.  The destructor checks whether
\verb|pq| is valid, and deletes it if it is.  The constructor and
destructor are implemented as follows:

\begin{verbatim}
s_merge_manager::s_merge_manager(void)
{
    pq = NULL;
}

s_merge_manager::~s_merge_manager(void)
{
    if (pq != NULL) {
        delete pq;
    }
}
\end{verbatim}

When \verb|AMI_partition_and_merge()| is called with a merge management
object of type \verb|s_merge_manager|, the first member functions called
are \verb|space_usage_overhead()| and\\ % 
\verb|space_usage_per_stream()|.  These return the number of bytes of main
memory that the merge management object will allocate when initialized.
\verb|space_usage_overhead()|'s return value indicates that space will be
needed for a priority queue.  \verb|space_usage_per_stream()|'s return
value indicates that for each input stream, space (which is to be allocated
when the priority queue is constructed) will be needed for an integer and
an arity type.

\begin{verbatim}
size_t s_merge_manager::space_usage_overhead(void)
{
    return sizeof(pqueue<arity_t,int>);
}


size_t s_merge_manager::space_usage_per_stream(void)
{
    return sizeof(arity_t) + sizeof(int);
}
\end{verbatim}

The next member function called by \verb|AMI_partition_and_merge()| is
\verb|main_mem_operate()|, which is called to handle the initial
substreams that are small enough to fit in main
memory.  Since we are sorting, we will simply use
quicksort.

\begin{verbatim}
AMI_err s_merge_manager::main_mem_operate(int* mm_stream, size_t len)
{
    qsort(mm_stream, len, sizeof(int), c_int_cmp);
    return AMI_ERROR_NO_ERROR;
}
\end{verbatim}

Having sorted all of the initial substreams,
\verb|AMI_partition_and_merge()| begins to merge them.  Before merging a
set of substreams, the merge management object's member function
\verb|initialize()| is called to inform the merge management object of the
number of streams it should be prepared to merge.  The object is also
provided with the first object from each of the streams to be merged.  For
objects of the class \verb|s_merge_manager|, the \verb|initialize()| member
function is as follows:

\begin{verbatim}
AMI_err s_merge_manager::initialize(arity_t arity, const int * const *in,
                                    AMI_merge_flag *taken_flags,
                                    int &taken_index)
{
    arity_t ii;

    input_arity = arity;

    if (pq != NULL) {
        delete pq;
    }

    // Construct a priority queue that can hold arity items.
    pq = new pqueue_heap_op(arity);

    for (ii = arity; ii--; ) {
        if (in[ii] != NULL) {
            taken_flags[ii] = 1;
            pq->insert(ii,*in[ii]);
        } else {
            taken_flags[ii] = 0;
        }
    }

    taken_index = -1;
    return AMI_MERGE_READ_MULTIPLE;
}
\end{verbatim}

Note the use of the return value \verb|AMI_MERGE_READ_MULTIPLE|.  This
indicates that the flags pointed to by \verb|*taken_flags| are set to
indicate which of the inputs were used and should not be presented
again.  This is very similar to the use of input flags to indicate
which inputs were used by a scan management object as described in
Section~\ref{sec:out-of-step}.  The reason that we have a special
return value to indicate when these flags are used is to increase
performance.  In order for \verb|AMI_scan()| to determine which inputs
were taken, it must examine all the flags.  In a many way merge, this
might be time consuming.  In cases where only one item is taken, its
index can be returned in \verb|taken_index| in order to save the time
that would be spent scanning the flags.  This technique is used in the
\verb|operate()| member function, whose implementation is as follows:

\begin{verbatim}
AMI_err s_merge_manager::operate(const int * const *in,
                                 AMI_merge_flag *taken_flags,
                                 int &taken_index,
                                 int *out)
{
    // If the queue is empty, we are done.  There should be no more
    // inputs.
    if (!pq->num_elts()) {
        return AMI_MERGE_DONE;
    } else {
        arity_t min_source;
        int min_t;

        pq->extract_min(min_source,min_t);
        *out = min_t;
        if (in[min_source] != NULL) {
            pq->insert(min_source,*in[min_source]);
            taken_index = min_source;
        } else {
            taken_index = -1;
        }
        return AMI_MERGE_OUTPUT;
    }
}
\end{verbatim}
\index{merging|)}

\comment{LA: Something here?}

\section{Distribution} \label{sec:distribution}
\index{Distribution}

\tobewritten

\comment{LA: We should look at the kb\_sort stuff and get it cleaned-up/done}

%Distribution has not been implemented in the current version of TPIE.
%It is primarily useful for parallel disks, and will be implemented in
%the parallel disk version of TPIE.  On a single disk, merging should
%be adequate for all applications where distribution might be
%considered.
%
%On a single disk, distribution will tend to result in algorithms that
%take roughly twice as long as similar algorithms that use merging.
%This is because distribution is done to the square root of the number
%of streams that can be buffered in main memory rather than the full
%number.  This results in recursion that is twice as deep.


\section{Sorting}

\subsection{Comparison Sorting} \label{sec:cmp-sorting}

\index{sorting!comparison|(}
Sorting is a common primitive operation in many algorithms.  It can be
performed in a variety of ways, such as by merging (See
Section~\ref{sec:merging}), distribution (See
Section~\ref{sec:distribution}), or Sharesort~\cite{aggarwal:optimal}. The
latter combines elements of both, along with simple bit permutations
(See Section~\ref{sec:bit-permuting}). TPIE provides a sort function
\verb|AMI_sort()| based on merging. In the future a number of other sorting
algorithms will be implemented and it is the intention that when
calling \verb|AMI_sort()|, TPIE should automatically select the best
algorithm for the given hardware platform.

%Because the best choice of sorting
%algorithm varies from one I/O system to the next, TPIE provides a single
%function \verb|AMI_sort()|, which selects an appropriate algorithm based on
%the underlying hardware characteristics.

\subsubsection{AMI\_sort()}
\verb|AMI_sort()| has three polymorphs. The first works on streams of
objects for which the operator \verb|<| is defined. It is invoked as
follows:

\begin{verbatim}
AMI_STREAM<int> instream;
AMI_STREAM<int> outstream;

void f()
{
    AMI_sort(&instream, &outstream);
}
\end{verbatim}

The second polymorph of \verb|AMI_sort()| uses an explicit function to
determine the relative order of two objects in the input stream.  This
is useful in cases where we may want to sort a stream of objects in
several different ways.  For example, the following code sorts a
stream of complex numbers in two ways, by their real parts and by
their imaginary parts.

\begin{verbatim}
class complex {
public:
    complex(double real_part, imaginary_part);
    double re(void);
    double im(void);
    ...
};

int compare_re(const complex &c1, const complex &c2)
{
    return (c1.re() < c2.re()) ? -1 :
           ((c1.re() > c2.re()) ? 1 : 0);
}

int compare_im(const complex &c1, const complex &c2)
{
    return (c1.im() < c2.im()) ? -1 :
           ((c1.im() > c2.im()) ? 1 : 0);
}

AMI_STREAM<complex> instream;
AMI_STREAM<complex> outstream_re;
AMI_STREAM<complex> outstream_im;

void f()
{
    AMI_sort(&instream, &outstream_re, compare_re);
    AMI_sort(&instream, &outstream_im, compare_im);
}
\end{verbatim}

The third polymorph of \verb|AMI_sort()| works like the second, except that
it relies on a comparator class instead of on a comparator function. In this
case the above complex number example would look at follows:\comment{LA:
Check that this is correct.}

\begin{verbatim}
class compare_re_class : comparator {
public:
    int compare_re(const complex &c1, const complex &c2) {
        return (c1.re() < c2.re()) ? -1 :
               ((c1.re() > c2.re()) ? 1 : 0);
    };
};

class compare_im_class : comparator {
public:
    int compare_im(const complex &c1, const complex &c2) {
        return (c1.im() < c2.im()) ? -1 :
               ((c1.im() > c2.im()) ? 1 : 0);
    };
};

AMI_STREAM<complex> instream;
AMI_STREAM<complex> outstream_re;
AMI_STREAM<complex> outstream_im;
compare_re_class compare_re
compare_im_class compare_im

void f()
{
    AMI_sort(&instream, &outstream_re, &compare_re);
    AMI_sort(&instream, &outstream_im, &compare_im);
}
\end{verbatim}

\comment{LA: We need to make the function object change!}


\subsubsection{Optimized Sort Functions}

Version \version~of TPIE also contains alpha versions of a new improved
sorting function\\ %
\verb|AMI_optimized_sort()| which has three polymorphs. It is planned that
after thorough testing this function will be the standard \verb|AMI_sort()|
function. Section~\ref{sec:ref-imp-ami-sort} provide more details with
regards to the difference in the implementation details between
\verb|AMI_optimized-sort()| and \verb|AMI_sort()|.

The first two polymorphs of \verb|AMI_optimized_sort()| are identical to
the first two \verb|AMI_sort()| polymorphs, which relies on the \verb|<|
operator and a comparison function, respectively.\comment{LA: We need to
add a comparator class polymorph also (when we do the function object
stuff). Doing so will also make it possible to clean up the
ami\_merge\_optimized.h code - right now there is two full copies of the
code.} The third polymorph is based on the assumption that the objects in
the input stream is to be sorted according to one of their fields (the
\verb|key| field), and that the class of this field have a well-defined
(possibly via overloading) \verb|<| operator. For example, consider the
class \verb|rectangle| below meant for axis parallel rectangles:

\begin{verbatim}}
class rectangle{
double northEast_x;
double northEast_y;
double southWest_x;
double southWest_y;
}
\end{verbatim}

and suppose that we want to sort a stream of rectangles in descending order
according to their \verb|southWest_y| coordinate. Assuming that the size
of each \verb|double| is 8 bytes, we simply sort the stream as follows:
 
\begin{verbatim}
AMI_STREAM<rectangle> instream;
AMI_STREAM<rectangle> outstream;
double dummyKey;

void f()
{
    AMI_optimized_sort(&instream, &outstream, 24, dummyKey);
}
\end{verbatim}

The third argument of \verb|AMI_optimized_sort()| is the offset within the
object of the \verb|key| according to which the items are to be sorted. The
fourth argument is a dummy argument having the same type as the key
field.\comment{LA: Maybe we should add something about this being a C++
requirement?}



\index{sorting!comparison|)}

\subsection{Key Bucket Sorting}
\label{sec:kb-sorting}

\index{sorting!key bucket|(}
\index{sorting!key bucket|)}

\tobewritten


\section{Permutation}

\subsection{General Permutation}

Permutation is a basic building block in many I/O algorithms. Routing a
general permutation in the I/O model is asymptotically as complex as
sorting~\cite{aggarwal:input}, though for some important classes of
permutations, such as BMMC permutations (See
Section~\ref{sec:bit-permuting}) faster algorithms are possible. In this
section, we discuss
\verb|AMI_general_permute()|, which routes arbitrary permutations, but
always takes as long as sorting, regardless of whether the particular
permutation can be done more quickly or not.

General permutations are routed using the function
\verb|AMI_general_permute()|.  Like other AMI functions,
\verb|AMI_general_permute()| relies on an operation management
object\index{operation management object} to determine its precise
behavior.  Unlike functions covered up to now, however, the type of
the operation management object\index{operation management object}
need not depend on the type of object in the stream being permuted.

A general permutation management object must provide two member
functions, \verb|initialize()| and \verb|destination()|.
\verb|initialize()| is called to inform the general permutation object
of the length of the stream to be permuted.  \verb|destination()| is
then called repeatedly to determine the destination for each object in
the stream based on it's initial position.

Here is an example of using general permutation to reverse the order
of the items in a stream.

\begin{verbatim}
class reverse_order : public AMI_gen_perm_object {
private:
    off_t total_size;
public:
    AMI_error initialize(off_t ts) { 
        total_size = ts; 
        return AMI_ERROR_NO_ERROR;
    };
    off_t destination(off_t source) {
        return total_size - 1 - source;
    };
};

AMI_STREAM<int> amis0, amis1;    

void f()
{
    reverse_order ro;

    AMI_general_permute(&amis0, &amis1, (AMI_gen_perm_object *)&ro);
}
\end{verbatim}

\subsection{Bit Permutation}
\label{sec:bit-permuting}

\comment{LA: Do we really want this in the tutorial?}

Bit permuting is a permutation technique in which the destination address
of a given item is computed by manipulating the bits of its source address.
The particular class of bit permutations that TPIE supports is the set of
bit matrix multiply complement (BMMC) permutations.  These permutations are
defined on sets of objects whose size is a power of 2.

Suppose we have an input consisting of $N = 2^n$ objects.  A BMMC
permutation on the input is defined by a nonsingular $n \times n$ bit
matrix $A$ and an $n$ element column vector $c$ of bits.  Source and
destination addresses are interpreted as column vectors of bits, with
the low order bit of the address at the top. The destination address
$x'$ corresponding to a given source address $x$ is computed as
$$x' = Ax + c$$ where addition and multiplication of matrix elements is
done over GF(2). For a detailed description of BMMC permutations,
see~\cite{cormen:integrate-tr}.

Routing BMMC permutations in TPIE is done using the
\verb|AMI_BMMC_permute()| entry point\comment{LA: Is it really
implemented?}, which takes an input stream, and output stream, and a
pointer to a bit permutation management object. In the following example,
we route a permutation that simply reverses the order of the source address
bits to produce the destination address.

First, we construct the matrices the permutation will use.
\index{bit_matrix@{\tt bit\_matrix}}
\begin{verbatim}
    bit_matrix A(n,n);
    bit_matrix c(n,1);

    {
        unsigned int ii,jj;

        for (ii = n; ii--; ) {
            c[ii][0] = 0;
            for (jj = n; jj--; ) {
                A[n-1-ii][jj] = (ii == jj);
            }
        }
    }
\end{verbatim}
Now we simply construct a permutation management object from the
matrices and perform the permutation.
\begin{verbatim}
    AMI_bit_perm_object bpo(A,c);
    
    ae = AMI_BMMC_permute(&amis0, &amis1, (AMI_bit_perm_object *)&bpo);
\end{verbatim}

\section{Distribution Sweeping} \label{sec:distsweep}
\index{Distribution sweeping}
\comment{LA: Get sweeping under distribution in the index}

\tobewritten

\section{Matrix Operations}
\label{sec:matrix}

\comment{LA: Read through this and check code.}

\index{matrices|(}

In addition to streams, which are linearly ordered collections of objects,
the AMI provides a mechanism for storing large matrices in external memory.
Matrices are a subclass of streams, and can thus be used with any of the
stream operations discussed above.  When a matrix is treated as a stream
its elements appear in row major order.  In addition to stream operations,
matrices support three simple arithmetic operations, addition, subtraction,
and multiplication.

It is assumed that the class \verb|T| of the elements in a matrix forms a
quasiring with the operators \verb|+| and \verb|*|.  Furthermore, the
object \verb|T((int)0)| is assumed to be an identity for \verb|+|.  At the
moment, it is not assumed that the operator
\verb|-| in an inverse of \verb|+|, and therefore no reduced
complexity matrix multiplication algorithms analogous to Strassen's
algorithm are used.

TPIE provides two different classes of matrices that, dense, and sparse.


\subsection{Dense Matrix Operations}
\label{sec:dense-mat}

\index{matrices!dense|(}

Dense matrices are implemented by the templated class
\verb|AMI_matrix|,\index{AMI_matrix@{\tt AMI\_matrix}} which is a subclass
of \verb|AMI_STREAM|.\index{AMI_STREAM@{\tt AMI\_STREAM}} Dense matrices
can be filled using \verb|AMI_scan()|, though typically they are filled
using the function \verb|AMI_matrix_fill()|, which uses a scan management
object that is given the row and column of each element of the matrix and
asked to fill them in.  In the following example, we create a 1000 by 1000
upper triangular matrix of ones and zeroes:

\begin{verbatim}
template<class T>
class fill_upper_tri : public AMI_matrix_filler<T> {
    AMI_err initialize(unsigned int rows, unsigned int cols)
    {
        return AMI_ERROR_NO_ERROR;
    };
    T element(unsigned int row, unsigned int col)
    {
        return (row <= col) ? T(1) : T(0);
    };
};

AMI_matrix m(1000, 1000);

void f()
{
    fill_upper_tri<double> fut;

    AMI_matrix_fill(&em, (AMI_matrix_filler<T> *)&fut);
}
\end{verbatim}

Arithmetic on dense matrices is performed in a straightforward way
using the functions \verb|AMI_matrix_add()|,
\verb|AMI_matrix_subtract()|, and \verb|AMI_matrix_multiply()|, as is
the following example:

\begin{verbatim}
AMI_matrix m0(1000, 500), m1(500, 2000), m2(1000, 2000);
AMI_matrix m3(1000, 500), m4(1000, 500);

void f()
{
    // Add m3 to m4 and put the result in m0.
    AMI_matrix_add(em3, em4, em0);
   
    // Multiply m0 by em1 to get m2.
    AMI_matrix_mult(em0, em1, em2);

    // Subtract m4 from m3 and put the result in m0.
    AMI_matrix_subtract(em3, em4, em0);        
}
\end{verbatim}

\index{matrices!dense|)}

\subsection{Sparse Matrix Operations}
\label{sec:sparse-mat}

\index{matrices!sparse|(}
\index{matrices!sparse|)}

\tobewritten


\subsection{Elementwise Arithmetic}
\label{sec:elementwise}

\index{arithmetic!elementwise|see{elementwise arithmetic}}
\index{elementwise arithmetic|(} 
The functions \verb|AMI_matrix_add()|
and \verb|AMI_matrix_subtract()| defined in
Section~\ref{sec:dense-mat} perform elementwise arithmetic on
matrices.  At times, we might also wish to perform elementwise
multiplication or division, or perform a scalar arithmetic operation
on all elements of a matrix.  TPIE provides mechanisms for doing this
not only on matrices, but on arbitrary streams, so long as they are of
objects for which the appropriate arithmetic operators (i.e. {\tt +},
{\tt -}, {\tt *}, {\tt /}) are defined.

Elementwise arithmetic is done with scan management objects
\index{operation management objects!scan} of the classes
\verb|AMI_scan_add|, \verb|AMI_scan_sub|, \verb|AMI_scan_mult| and
\verb|AMI_scan_div|.  Here is an example that performs
elementwise division on the elements of two streams.

\begin{verbatim}
#include <ami_stream_arith.h>

void foo()
{
    AMI_STREAM<int> amis0;
    AMI_STREAM<int> amis1;
    AMI_STREAM<int> amis2;

    AMI_scan_div<int> sd;

    // Divide each element of amis0 by the corresponding element of
    // amis1 and put the result in amis2.
    AMI_scan(&amis0, &amis1, &sd, &amis2);
}
\end{verbatim}
\index{elementwise arithmetic|)}

\index{matrices|)}


\section{External Stack}
\label{sec:stack}

\index{External Stack}

\comment{LA: put stack, external in index}

\tobewritten

\section{Compiling and Executing a TPIE Program}
\label{sec:compiling}

The fragments of code presented in this tutorial are valuable for
instructive purposes, however, they are incomplete. In order to
successfully compile, link, and run a complete TPIE application, some
additional code and configuration is needed. The configuration and
compilation of a TPIE program is discussed below. The recommended way for a
novice TPIE programmer to learn how to write a complete TPIE application is
to go through the sample program of Chapter~\ref{ch:samplepgmr} or to look
at the source code provided in the \verb|test| directory.

The exact behavior or TPIE at run time is controlled by several
macros. These macros are normally defined in the file \verb|app_config.h|
\index{app_config@{\tt app\_config.h}} which is included in the beginning
of any TPIE program before including any TPIE headers. The test application
code\index{test applications} distributed with TPIE contains such a file
(in \verb|/test/app_config.h|). See Section~\ref{sec:tuning} for a
discussion of the macros and of how they should be set on a given hardware
platform in order to obtain maximal performance.

Once the appropriate macros have been defined, TPIE's templated classes and
functions are included by including the header file \verb|ami.h| from the
\verb|include| directory. Normally, this directory is pointed to by a
\verb|-I| argument to the compiler. In order to instruct TPIE to run with a
user-specified amount of internal memory the variable \verb|register_new|
has to be set to 1 in the main body of the program. Setting this variable
means that the program will abort if the allocated internal memory exceeds
a specified amount.\comment{LA: Something about how TPIE counts memory?}
This amount is set by the function \verb|MM_manager.resize_heap(mm_size)|
which instructs the TPIE memory manager \verb|MM_manager| to disallow the
applications total internal memory usage (in the ``heap'' area) from
exceeding \verb|test_mm_size| bytes. It is the responsibility of the
application to have the \verb|MM_manager| ``resize'' its heap to an
appropriate size. Normally, this amount is the amount of physical main
memory minus the main memory used by the operating system and other
programs running on the machine. If \verb|register_new| is set to 0, the
application will run with virtual memory like an ordinary non-TPIE
application would.

If the application program is stored in the file \verb|foo.cpp| it can now be
compiled with the following command:

\begin{verbatim}
g++ foo.cpp -I ../include/ -L ../lib/ -ltpie -o foo
\end{verbatim}

Users interested in setting up a \verb|Makefile| for the compiling task can
look at a sample \verb|Makefile| in the \verb|test| directory.


\chapter{Additional Examples} \label{ch:examples}
\index{examples}

This chapter contains some additional annotated examples of 
TPIE application code.\comment{LA: Is this chapter still ok?}

\section{Convex Hull}
\label{sec:convex-hull}
\index{convex hull|(}

The convex hull of a set of points in the plane is the smallest convex
polygon which encloses all of the points.  Graham's scan is a simple
algorithm for computing convex hulls.  It should be discussed in any
introductory book on computational geometry, such
as~\cite{preparata:computational}.  Although Graham's scan was not
originally designed for external memory, it can be implemented optimally in
this setting.  What is interesting about this implementation is that
external memory stacks are used within the implementation of a scan
management object.

First, we need a data type for storing points.  We use the following
simple class, which is templated to handle any numeric type.

\begin{verbatim}
template<class T>
class point {
public:
    T x;
    T y;
    point() {};
    point(const T &rx, const T &ry) : x(rx), y(ry) {};
    ~point() {};

    inline int operator==(const point<T> &rhs) const {
        return (x == rhs.x) && (y == rhs.y);
    }
    inline int operator!=(const point<T> &rhs) const {
        return (x != rhs.x) || (y != rhs.y);
    }

    // Comparison is done by x.
    int operator<(const point<T> &rhs) const {
        return (x < rhs.x);
    }

    int operator>(const point<T> &rhs) const {
        return (x > rhs.x);
    }
    
    friend ostream& operator<<(ostream& s, const point<T> &p);
    friend istream& operator>>(istream& s, point<T> &p);
};
\end{verbatim}

Once the points are s by their $x$ values, we simply scan them to
produce the upper and lower hulls, each of which are stored as a stack
pointed to by the scan management object.  We then concatenate the
stacks to produce the final hull.  The code for computing the convex
hull of a set of points is thus

\begin{verbatim}
template<class T>
AMI_err convex_hull(AMI_STREAM< point<T> > *instream,
                    AMI_STREAM< point<T> > *outstream)
{
    AMI_err ae;

    point<T> *pt;

    AMI_stack< point<T> > uh((unsigned int)0, instream->stream_len());
    AMI_stack< point<T> > lh((unsigned int)0, instream->stream_len());

    AMI_STREAM< point<T> > in_sort;
        
    // Sort the points by x.

    ae = AMI_sort(instream, &in_sort);
    
    // Compute the upper hull and lower hull in a single scan.

    scan_ul_hull<T> sulh;

    sulh.uh_stack = &uh;
    sulh.lh_stack = &lh;
    
    ae = AMI_scan(&in_sort, &sulh);

    // Copy the upper hull to the output.

    uh.seek(0);
    
    while (1) {
        ae = uh.read_item(&pt);
        if (ae == AMI_ERROR_END_OF_STREAM) {
            break;
        } else if (ae != AMI_ERROR_NO_ERROR) {
            return ae;
        }

        ae = outstream->write_item(*pt);
        if (ae != AMI_ERROR_NO_ERROR) {
            return ae;
        }
    }
    
    // Reverse the lower hull, concatenating it onto the upper hull.

    while (lh.pop(&pt) == AMI_ERROR_NO_ERROR) {
        ae = outstream->write_item(*pt);
        if (ae != AMI_ERROR_NO_ERROR) {
            return ae;
        }
    }

    return AMI_ERROR_NO_ERROR;
}
\end{verbatim}

The only thing that remains is to define a scan management object that
is capable of producing the upper and lower hulls by scanning the
points.  According to the Graham's scan algorithm, we produce the
upper hull by moving forward in the $x$ direction, adding each
point we encounter to the upper hull, until we find one that induces a
concave turn on the surface of the hull.  We then move backwards
through the list of points that have been added to the hull,
eliminating points until a convex path is reestablished.  This process
is made efficient by storing the points on the hull so far in a stack.
The code for the scan management object, which relies on the function
\verb|ccw()| to actually determine whether a corner is
convex or not, is as follows:

\begin{verbatim}
template<class T>
class scan_ul_hull : AMI_scan_object {
public:
    AMI_stack< point <T> > *uh_stack, *lh_stack;

    scan_ul_hull(void);
    virtual ~scan_ul_hull(void);
    AMI_err initialize(void);
    AMI_err operate(const point<T> &in, AMI_SCAN_FLAG *sfin);
};

template<class T>
scan_ul_hull<T>::scan_ul_hull(void) : uh_stack(NULL), lh_stack(NULL)
{
}

template<class T>
scan_ul_hull<T>::~scan_ul_hull(void)
{
}

template<class T>
AMI_err scan_ul_hull<T>::initialize(void)
{
    return AMI_ERROR_NO_ERROR;
}


template<class T>
AMI_err scan_ul_hull<T>::operate(const point<T> &in,
                                 AMI_SCAN_FLAG *sfin)
{
    AMI_err ae;

    // If there is no more input we are done.
    if (!*sfin) {
        return AMI_SCAN_DONE;
    }

    if (!uh_stack->stream_len()) {

        // If there is nothing on the stacks then put the first point
        // on them.
        ae = uh_stack->push(in);
        if (ae != AMI_ERROR_NO_ERROR) {
            return ae;
        }

        ae = lh_stack->push(in);
        if (ae != AMI_ERROR_NO_ERROR) {
            return ae;
        }

    } else {

        // Add to the upper hull.

        {
            // Pop the last two points off.

            point<T> *p1, *p2;

            tp_assert(uh_stack->stream_len() >= 1, "Stack is empty.");
            
            uh_stack->pop(&p2);

            // If the point just popped is equal to the input, then we
            // are done.  There is no need to have both on the stack.
            
            if (*p2 == in) {
                uh_stack->push(*p2);
                return AMI_SCAN_CONTINUE;
            }
            
            if (uh_stack->stream_len() >= 1) {
                uh_stack->pop(&p1);
            } else {
                p1 = p2;
            }
            
            // While the turn is counter clockwise and the stack is
            // not empty pop another point.
            
            while (1) {                
                if (ccw(*p1,*p2,in) >= 0) {
                    // It does not turn the right way.  The points may
                    // be colinear.
                    if (uh_stack->stream_len() >= 1) {
                        // Move backwards to check another point.
                        p2 = p1;
                        uh_stack->pop(&p1);
                    } else {
                        // Nothing left to pop, so we can't move
                        // backwards.  We're done.
                        uh_stack->push(*p1);
                        if (in != *p1) {
                            uh_stack->push(in);
                        }
                        break;
                    }
                } else {
                    // It turns the right way.  We're done.
                    uh_stack->push(*p1);
                    uh_stack->push(*p2);
                    uh_stack->push(in);
                    break;
                }
            }
        }

        // Add to the lower hull.

        {
            // Pop the last two points off.

            point<T> *p1, *p2;

            tp_assert(lh_stack->stream_len() >= 1, "Stack is empty.");
            
            lh_stack->pop(&p2);

            // If the point just popped is equal to the input, then we
            // are done.  There is no need to have both on the stack.
            
            if (*p2 == in) {
                lh_stack->push(*p2);
                return AMI_SCAN_CONTINUE;
            }
            
            if (lh_stack->stream_len() >= 1) {
                lh_stack->pop(&p1);
            } else {
                p1 = p2;
            }
            
            // While the turn is clockwise and the stack is
            // not empty pop another point.
            
            while (1) {                
                if (ccw(*p1,*p2,in) <= 0) {
                    // It does not turn the right way.  The points may
                    // be colinear.
                    if (lh_stack->stream_len() >= 1) {
                        // Move backwards to check another point.
                        p2 = p1;
                        lh_stack->pop(&p1);
                    } else {
                        // Nothing left to pop, so we can't move
                        // backwards.  We're done.
                        lh_stack->push(*p1);
                        if (in != *p1) {
                            lh_stack->push(in);
                        }
                        break;
                    }
                } else {
                    // It turns the right way.  We're done.
                    lh_stack->push(*p1);
                    lh_stack->push(*p2);
                    lh_stack->push(in);
                    break;
                }
            }
        }       
    }

    return AMI_SCAN_CONTINUE;    
}
\end{verbatim}

The function \verb|ccw()| computes twice the signed area of a triangle in
the plane by evaluating a 3 by 3 determinant.  The result is positive
if and only if the the three points in order form a counterclockwise
cycle.

\begin{verbatim}
template<class T>
T ccw(const point<T> &p1, const point<T> &p2, const point<T> &p3)
{
    T sa;
    
    sa = ((p1.x * p2.y - p2.x * p1.y) -
          (p1.x * p3.y - p3.x * p1.y) +
          (p2.x * p3.y - p3.x * p2.y));

    return sa;
}
\end{verbatim}
\index{convex hull|)}

\section{List-Ranking}
\label{sec:list-ranking}
\index{list ranking|(}

List ranking is a fundamental problem in graph theory.  The problem is
as follows: We are given the directed edges of a linked list in some
arbitrary order.  Each edge is an ordered pair of node ids.  The first
is the source of the edge and the second is the destination of the
edge.  Our goal is to assign a weight to each edge corresponding to
the number of edges that would have to be traversed to get from the
head of the list to that edge.

The code given below solves the list ranking problem using a simple
randomized algorithm due to Chiang {\em et al}.~\cite{chiang:external}.
As was the case in the code examples in the tutorial in
Chapter~\ref{ch:tutorial}, \verb|#include| statements
for header files and definitions of some classes and functions as well
as some error and consistency checking code are left out so that the
reader can concentrate on the more important details of how TPIE is
used.  A complete ready to compile version of this code is included in
the TPIE source distribution.

First, we need a class to represent edges.  Because the algorithm will
set a flag for each edge and then assign weights to the edges, we
include fields for these values.

\begin{verbatim}
class edge {
public:
    unsigned long int from;        // Node it is from
    unsigned long int to;          // Node it is to
    unsigned long int weight;      // Position when ranked.
    bool flag;            // A flag used to randomly select some edges.

    friend ostream& operator<<(ostream& s, const edge &e);
};    
\end{verbatim}

As the algorithm runs, it will sort the edges.  At times this will be
done by their sources and at times by their destinations.  The
following simple functions are used to compare these values:

\begin{verbatim}
int edgefromcmp(CONST edge &s, CONST edge &t)
{
    return (s.from < t.from) ? -1 : ((s.from > t.from) ? 1 : 0);
}
  
int edgetocmp(CONST edge &s, CONST edge &t)
{
    return (s.to < t.to) ? -1 : ((s.to > t.to) ? 1 : 0);
}
\end{verbatim}

The first step of the algorithm is to assign a randomly chosen flag,
whose value is 0 or 1 with equal probability, to each edge.  This is
done using \verb|AMI_scan()| with a scan management object of the
class \verb|random_flag_scan|, which is defined as follows:

\begin{verbatim}
class random_flag_scan : AMI_scan_object {
public:
    AMI_err initialize(void);  
    AMI_err operate(const edge &in, AMI_SCAN_FLAG *sfin,
                    edge *out, AMI_SCAN_FLAG *sfout);
};

AMI_err random_flag_scan::initialize(void) {
    return AMI_ERROR_NO_ERROR;
}

AMI_err random_flag_scan::operate(const edge &in, AMI_SCAN_FLAG *sfin,
                                  edge *out, AMI_SCAN_FLAG *sfout)
{ 
    if (!(sfout[0] = *sfin)) {
        return AMI_SCAN_DONE;
    }
    *out = in;
    out->flag = (random() & 1);
    
    return AMI_SCAN_CONTINUE;
}
\end{verbatim}

The next step of the algorithm is to separate the edges into an active
list and a cancel list.  In order to do this, we sort one copy of the
edges by their sources (using \verb|edgefromcmp|) and sort another copy by
their destinations (using \verb|edgetocmp|).  We then call
\verb|AMI_scan()| to scan the two lists and produce an active list and
a cancel list.  A scan management object of class
\verb|separate_active_from_cancel|, which is defined below, is used.

\begin{verbatim}
////////////////////////////////////////////////////////////////////////
// separate_active_from_cancel
//
// A class of scan object that takes two edges, one to a node and one 
// from it, and writes an active edge and possibly a canceled edge.
//
// Let e1 = (x,y,w1,f1) be the first edge and e2 = (y,z,w2,f2) the second.
// If e1's flag (f1) is set and e2's (f2) is not, then we write 
// (x,z,w1+w2,?) to the active list and e2 to the cancel list.  The
// effect of this is to bridge over the node y with the new active edge.
// f2, which was the second half of the bridge, is saved in the cancellation
// list so that it can be ranked later after the active list is recursively 
// ranked.
//
// Since all the flags should have been set randomly before this function
// is called, the expected size of the active list is 3/4 the size of the
// original list.
////////////////////////////////////////////////////////////////////////
class separate_active_from_cancel : AMI_scan_object {
public:
    AMI_err initialize(void);
    AMI_err operate(CONST edge &e1, CONST edge &e2, AMI_SCAN_FLAG *sfin,
                    edge *active, edge *cancel, AMI_SCAN_FLAG *sfout);
};

AMI_err separate_active_from_cancel::initialize(void)
{
    return AMI_ERROR_NO_ERROR;
}

// e1 is from the list of edges sorted by where they are from.
// e2 is from the list of edges sorted by where they are to.
AMI_err separate_active_from_cancel::operate(CONST edge &e1,
                                             CONST edge &e2, 
                                             AMI_SCAN_FLAG *sfin,
                                             edge *active, edge *cancel, 
                                             AMI_SCAN_FLAG *sfout)
{
    // If we have both inputs.
    if (sfin[0] && sfin[1]) {
        // If they have a node in common we may be in a bridging situation.
        if (e2.to == e1.from) {
            // We will write to the active list no matter what.
            sfout[0] = 1;
            *active = e2;
            if (sfout[1] = (e2.flag && !e1.flag)) {
                // Bridge.  Put e1 on the cancel list and add its
                // weight to the active output.
                active->to = e1.to;
                active->weight += e1.weight;
                *cancel = e1;
                sfout[1] = 1;
            } else {
                // No bridge.
                sfout[1] = 0;
            }
        } else {
            // They don't have a node in common, so one of them needs
            // to catch up with the other.  What happened is that
            // either e2 is the very last edge in the list or e1 is
            // the very first or we just missed a bridge because of
            // flags.
            sfout[1] = 0;                
            if (e2.to > e1.from) {
                // e1 is behind, so just skip it.
                sfin[1] = 0;
                sfout[0] = 0;
            } else {
                // e2 is behind, so put it on the active list.
                sfin[0] = 0;
                sfout[0] = 1;
                *active = e2;
            }
        }
        return AMI_SCAN_CONTINUE;
    } else {
        // If we only have one input, either just leave it active.
        if (sfin[0]) {
            *active = e1;
            sfout[0] = 1;
            sfout[1] = 0;
            return AMI_SCAN_CONTINUE;
        } else if (sfin[1]) {
            *active = e2;
            sfout[0] = 1;
            sfout[1] = 0;
            return AMI_SCAN_CONTINUE;
        } else {
            // We have no inputs, so we're done.
            sfout[0] = sfout[1] = 0;            
            return AMI_SCAN_DONE;
        }
    }
}
\end{verbatim}

The next step of the algorithm is to strip the cancelled edges away
from the list of all edges.  The remaining active edges will form a
recursive subproblem.  Again, we use a scan management object, this
time of the class \verb|strip_active_from_cancel|, which is defined as
follows:

\begin{verbatim}
////////////////////////////////////////////////////////////////////////
//
// strip_cancel_from_active
//
// A scan management object to take an active list and remove the
// smaller weighted edge of each pair of consecutive edges with the
// same destination.  The purpose of this is to strip edges out of the
// active list that were sent to the cancel list.
//
////////////////////////////////////////////////////////////////////////
class strip_cancel_from_active : AMI_scan_object {
private:
    bool holding;
    edge hold;
public:
    AMI_err initialize(void);  
    AMI_err operate(const edge &active, AMI_SCAN_FLAG *sfin,
                    edge *out, AMI_SCAN_FLAG *sfout);
};

AMI_err strip_cancel_from_active::initialize(void) {
    holding = false;
    return AMI_ERROR_NO_ERROR;
}

// Edges should be sorted by destination before being processed by
// this object.
AMI_err strip_cancel_from_active::operate(const edge &active,
                                  AMI_SCAN_FLAG *sfin,
                                  edge *out, AMI_SCAN_FLAG *sfout)
{
    // If no input then we're done, except that we might still be
    // holding one.
    if (!*sfin) {
        if (holding) {
            *sfout = 1;
            *out = hold;
            holding = false;
            return AMI_SCAN_CONTINUE;
        } else {
            *sfout = 0;
            return AMI_SCAN_DONE;
        }
    }

    if (!holding) {
        // If we are not holding anything, then just hold the current
        // input.
        hold = active;
        holding = true;
        *sfout = 0;
    } else {
        *sfout = 1;
        
        if (active.to == hold.to) {
            if (active.weight > hold.weight) {
                *out = active;
            } else {
                *out = hold;
            }

            holding = false;
        } else {
            *out = hold;
            hold = active;
        }
    }

    return AMI_SCAN_CONTINUE;
}
\end{verbatim}

After recursion, we must patch the cancelled edges back into the
recursively ranked list of active edges.  This is done using a scan
with a scan management object of the class
\verb|interleave_active_cancel|, which is implemented as follows:

\begin{verbatim}
////////////////////////////////////////////////////////////////////////
// interleave_active_cancel
//
// This is a class of merge object that merges two lists of edges
// based on their to fields.  The first list of edges should be active
// edges, while the second should be cancelled edges.  When we see two
// edges with the same to field, we know that the second was cancelled
// when the first was made active.  We then fix up the weights and
// output the two of them, one in the current call and one in the next
// call.
//
// The streams this operates on should be sorted by their terminal
// (to) nodes before AMI_scan() is called.
// 
////////////////////////////////////////////////////////////////////////

class patch_active_cancel : AMI_scan_object {
private:
    bool holding;
    edge hold;
public:
    AMI_err initialize(void);
    AMI_err operate(CONST edge &active, CONST edge &cancel,
                    AMI_SCAN_FLAG *sfin,
                    edge *patch, AMI_SCAN_FLAG *sfout);
};

AMI_err patch_active_cancel::initialize(void)
{
    holding = false;
    return AMI_ERROR_NO_ERROR;
}

AMI_err patch_active_cancel::operate(CONST edge &active, CONST edge &cancel,
                                     AMI_SCAN_FLAG *sfin,
                                     edge *patch, AMI_SCAN_FLAG *sfout)
{
    // Handle the special cases that occur when holding an edge and/or
    // completely out of input.
    if (holding) {
        sfin[0] = sfin[1] = 0;
        *patch = hold;
        holding = false;
        *sfout = 1;
        return AMI_SCAN_CONTINUE;
    } else if (!sfin[0]) {
        *sfout = 0;
        return AMI_SCAN_DONE;
    }

    if (!sfin[1]) {
        // If there is no cancel edge (i.e. all have been processed)
        // then just pass the active edge through.
        *patch = active;
    } else {
        if (holding = (active.to == cancel.to)) {
            patch->from = active.from;
            patch->to = cancel.from;
            patch->weight = active.weight - cancel.weight;
            hold.from = cancel.from;
            hold.to = active.to;
            hold.weight = active.weight;
        } else {
            *patch = active;
            sfin[1] = 0;
        }
    }

    *sfout = 1;
    return AMI_SCAN_CONTINUE;

}
\end{verbatim}

Finally, here is the actual function to rank the list.

\begin{verbatim}
////////////////////////////////////////////////////////////////////////
// list_rank()
//
// This is the actual recursive function that gets the job done.
// We assume that all weights are 1 when the initial call is made to
// this function.
//
// Returns 0 on success, nonzero otherwise.
////////////////////////////////////////////////////////////////////////

int list_rank(AMI_STREAM<edge> *istream, AMI_STREAM<edge> *ostream)
{
    AMI_err ae;
    
    off_t stream_len = istream->stream_len();

    AMI_STREAM<edge> *edges_rand;
    AMI_STREAM<edge> *active;
    AMI_STREAM<edge> *active_2;
    AMI_STREAM<edge> *cancel;
    AMI_STREAM<edge> *ranked_active;

    AMI_STREAM<edge> *edges_from_s;
    AMI_STREAM<edge> *cancel_s;
    AMI_STREAM<edge> *active_s;
    AMI_STREAM<edge> *ranked_active_s;

    // Scan/merge management objects.
    random_flag_scan my_random_flag_scan;
    separate_active_from_cancel my_separate_active_from_cancel;
    strip_cancel_from_active my_strip_cancel_from_active;
    patch_active_cancel my_patch_active_cancel;
    
    // Check if the recursion has bottomed out.  If so, then read in the
    // array and rank it.

    {
        size_t mm_avail;
        
        MM_manager.available(&mm_avail);

        if (stream_len * sizeof(edge) < mm_avail / 2) {
            edge *mm_buf = new edge[stream_len];
            istream->seek(0);
            istream->read_array(mm_buf,&stream_len);
            main_mem_list_rank(mm_buf,stream_len);
            ostream->write_array(mm_buf,stream_len);
            return 0;
        }
    }
    
    // Flip coins for each node, setting the flag to 0 or 1 with equal
    // probability.

    edges_rand = new AMI_STREAM<edge>;
    
    AMI_scan(istream, &my_random_flag_scan, edges_rand);

    // Sort one stream by source.  The original input was sorted by
    // destination, so we don't need to sort it again.

    edges_from_s = new AMI_STREAM<edge>;

    ae = AMI_sort(edges_rand, edges_from_s, edgefromcmp);

    // Scan to produce and active list and a cancel list.

    active = new AMI_STREAM<edge>;
    cancel = new AMI_STREAM<edge>;

    ae = AMI_scan(edges_from_s, edges_rand,
                  &my_separate_active_from_cancel,
                  active, cancel);

    delete edges_from_s;
    delete edges_rand;
    
    // Strip the edges that went to the cancel list out of the active list.

    active_s = new AMI_STREAM<edge>;

    ae = AMI_sort(active, active_s, edgetocmp);

    delete active;

    active_2 = new AMI_STREAM<edge>;

    ae = AMI_scan(active_s,
                  &my_strip_cancel_from_active,
                  active_2);

    delete active_s;

    // Recurse on the active list.  The list we pass in is sorted by
    // destination.  The recursion will return a list sorted by
    // source.

    ranked_active = new AMI_STREAM<edge>;
    
    list_rank(active_2, ranked_active);

    delete active_2;

    cancel_s = new AMI_STREAM<edge>;

    AMI_sort(cancel, cancel_s, edgetocmp);

    delete cancel;

    // The output of the recursive call is not necessarily sorted by
    // destination.  We'll make it so before we try to merge in the
    // cancel list.

    ranked_active_s = new AMI_STREAM<edge>;

    AMI_sort(ranked_active, ranked_active_s, edgetocmp);

    delete ranked_active;
    
    // Now merge the recursively ranked active list and the sorted 
    // cancel list.

    ae = AMI_scan(ranked_active_s, cancel_s,
                  &my_patch_active_cancel, ostream);

    delete ranked_active_s;
    delete cancel_s;
    
    return 0;
}
\end{verbatim}

Our recursion bottoms out when the problem is small enough to fit
entirely in main memory, in which case we read it in and call a
function to rank a list in main memory.  The details of this function
are omitted here.

\begin{verbatim}
////////////////////////////////////////////////////////////////////////
// main_mem_list_rank()
//
// This function ranks a list that can fit in main memory.  It is used
// when the recursion bottoms out.
//
////////////////////////////////////////////////////////////////////////

int main_mem_list_rank(edge *edges, size_t count)
{
    // Rank the list in main memory

    ...
        
    return 0;  
}
\end{verbatim}
\index{list ranking|)}

\section{NAS Parallel Benchmarks}

\tobeextended

Code designed to implement external memory versions of a number of the
NAS parallel benchmarks is included with the TPIE distribution.
Examine this code for examples of how the various primitives TPIE
provides can be combined into powerful applications capable of solving
real-world problems.

Detailed descriptions of the NAS parallel benchmarks are available
from the \htmladdnormallink{NAS Parallel Benchmark Home Page}%
{http://www.nas.nasa.gov/NAS/NPB/}
\begin{latexonly}
at URL \verb|http://www.nas.nasa.gov/NAS/NPB/|.
\end{latexonly}

\section{Spatial Join}

\tobewritten

\comment{LA: Distribution sweeping, SSSJ, ect}

\comment{LA: Someting about R-tree building and drainage networks at some point}