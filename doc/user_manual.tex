%%
%% $Id: user_manual.tex,v 1.25 2002-06-27 00:24:47 tavi Exp $
%%
\chapter{Overview}

The data sets involved in some modern applications are too large to
fit in the main memory of even the most powerful computers and must therefore
reside on disk. Thus communication between internal and external memory,
and not actual computation time, often becomes the bottleneck in the
computation. This is due to the huge difference in access time of fast
internal memory and slower external memory such as disks. While typical
access time of main memory is measured in nanoseconds, a typical access
time of a disk is on the order of milliseconds~\cite{cockcroft:sun}. So
roughly speaking there is a factor of a million difference in the access
time of internal and external memory. A good example of an applications
involving massive amounts of geometric data is NASA's Earth Observation
System (EOS)~\cite{cromp,kobler:nasa}, which is expected to manipulate
petabytes (thousands of terabytes, or millions of gigabytes) of data.

The goal of theoretical work in the area of {\em external
   memory (EM) algorithms\/} (also called {\em I/O
   algorithms\/} or {\em out-of-core algorithms}) is to
eliminate or minimize the I/O bottleneck through better
algorithm design.

In order to cope with the high cost of accessing data,
efficient EM algorithms exploit locality in their design.
They access a large \emph{block} of $B$ contiguous data
elements at a time and perform the necessary algorithmic
steps on the elements in the block while in the high-speed
memory. The speedup can be considerable.
A second effective strategy for EM algorithms is the use of
multiple parallel disks; whenever an input/output operation
is performed, $D$ blocks are transferred in parallel between
memory and each of the $D$ disks (one block per disk).

The study of EM algorithm design was effectively started in
the late eighties by Aggarwal and
Vitter~\cite{aggarwal:input} and an important model for
designing I/O algorithms called the Parallel Disk Model
(PDM) was later proposed by Vitter and
Shriver~\cite{vitter:parmem1}. The PDM proposed that a
good EM algorithm should transfer data between main memory
and disk in a blocked manner, and should use all of the
available disks concurrently. An optimal EM algorithm under
this model minimizes the number of such blocked, parallel
I/O operations it performs.
 
Subsequently, I/O algorithms for the PDM (mostly with a
single disk and single processor) have been developed for
many problem domains, including computational
geometry~\cite{aapv-fibld-01,goodrich:external,arge:buffer,arge:theory,arge:gis,aamvv-empgbtag97,arge:interval,kanellakis:indexing,ramaswamy:path,subramanian:p-range,vengroff:efficient,agarwal:efficient,zhu:further,agarwal:point,arge:scalable,arge:theory,callahan:topology,franciosa:orders,grossi:cross-tree,arge:tpie},
\index{computational geometry} graph
algorithms~\cite{chiang:external,arge:buffer,kumar:improved,abello:functional,crauser:randomized,arge:obdd,feuerstein:memory,nodine:blocking,ullman:input},
\index{graph algorithms} and string
processing~\cite{ferragina:fully,ferragina:fast,arge:strings,crauser:construction}.

The use of parallel disks\index{parallel disks}
\index{disks!parallel|see{parallel disks}} has also received
some theoretical
attention~\cite{vitter:parmem1,nodine:deterministic,nodine:greed,dehne:efficient,dehne:reducing}.
There are more complicated models than the PDM, designed to
address the I/O bottleneck in different ways. These include
models that address the communication bottleneck between
multiple layers in
memory hierarchies~\cite{}, and models incorporating
parallel processors as well as parallel
disks~\cite{cormen:challenge,dehne:efficient,dehne:reducing}.

Implementations of these theoretical results are scarce.
TPIE, {\em a Transparent Parallel I/O Environment}, is
intended to bridge the gap between the theory and practice
of parallel I/O systems. On one hand, TPIE attempts to
provide usable implementations of (sometimes complex)
theoretical algorithms, feeding back that experience to
algorithm designers. On the other hand, TPIE also
accommodates the use of heuristics from the practice of I/O
algorithms in order to achieve maximum performance. Other EM
implementation work includes benchmarking of certain
geometric I/O algorithms by Chiang\cite{chiang:experiments},
experiments with FFT and related algorithms by Cormen et
al.~\cite{cormen:ffts}, implementation of the buffer tree
\cite{arge:buffer} by Hutchinson et~al.~\cite{hutchinson:early}, and the
LEDA-SM system for
implementing data types by Crauser et al.\cite{mehlhorn:ledasm}.  Surveys
of previous work in EM algorithm design and implementation
can be found
in~\cite{arge:gisbook,arge:thesis,vitter:dimacssurvey}

%As of today, gigabyte computer systems exist on desktops, and terabyte
%systems are not unheard of.  In the not too distant future, systems
%designed to manage petabytes of information will come on-line.  The most
%important characteristic of such vast amounts of data is that they cannot
%possibly be stored in the primary memories of even the most powerful
%computers. Instead, they must be stored on secondary memory, such as
%magnetic disks, or tertiary memory, such as tapes and optical memory.
%Compared to CPUs and solid state random access memory, these devices are
%extremely slow; the difference in access time is typically 2 to 5
%orders of magnitude. Because of the low speed of secondary storage, good
%performance in the Input/Output (I/O) system that links secondary storage
%to main memory and the CPU or CPUs is critical if good performance is to be
%achieved overall. Performance can be further improved if many disks can be
%efficiently used in parallel. Unfortunately, existing I/O systems generally
%do not perform adequately~\cite{patt:computer}.

%Recently, a number of parallel I/O systems have become
%available, though in most cases they have failed to take adequate advantage
%of the insights theorists have had to offer \cite{cormen:integrate-tr}.

The objectives of the TPIE
project include the following:

\begin{itemize}
    \item {\em Abstract away the details of how I/O is
       performed} so that programmers need only deal with a
    simple high level interface.
    \item {\em Provide a collection of I/O-optimal
       paradigms} for large scale computation that are
    efficient not only in theory, but also in practice.
    \item {\em Be flexible}, allowing programmers to specify
    the functional details of computation taking place
    within the supported paradigms.  This will allow a wide
    variety of algorithms to be implemented within the
    system.
    \item {\em Be portable} across a variety hardware
    platforms.
    \item {\em Be extensible}, so that new features can be
    easily added later.
\end{itemize}

TPIE is implemented as a set of templated classes and
functions in C++.\index{C++} It also includes a small
library and a set of test and sample applications.

\section{Hardware Platforms}
\index{hardware platforms}

TPIE has been tested on a variety of hardware platforms with a variety of
UNIX operating systems. Combinations that have been tested
include:
\begin{itemize}
\item Sun Sparc/Solaris 5.x
\item DEC Alpha/Digital Unix 4.0
\item DEC Alpha/FreeBSD 4.0
\item Intel Pentium/FreeBSD 4.0
\item Intel Pentium/Solaris 5.x
\end{itemize}


\section{Future releases}
\index{Future releases}
\index{Releases!future|see{future releases}}

The TPIE system is a research tool that is constantly
evolving.  The current release of TPIE (\version) includes
the fundamental routines for solving fundamental {\em
   batched} problems such as sorting. These routines enable
the programmer to write efficient and portable
implementations of algorithms that makes use of fundamental
{\em streaming}
primitives~\cite{arge:gisbook,vitter:podssurvey}. Relative
to versions 0.8.02a and 0.9.01a, the current version of TPIE
has been updated to improve performance and a number of
bugs have been fixed. This manual has been updated to
reflect these changes and several chapters have been
expanded in order to allow the TPIE programmer to tune the
system for best performance on a given platform. A list of
the major changes can be found on the TPIE web page at
\myverb{http://www.cs.duke.edu/TPIE/}. The
TPIE project is work in progress -- several major planned
components have not yet been implemented and work is also
being done to update and extend the current manual. Users of
TPIE are encouraged to send bug reports, etc., to
\verb|tpie@cs.duke.edu|.

Extensions and/or improvements to TPIE are in progress.
Projects include further performance improvements, support
for parallel disks, addition of the distribution sweeping
primitive~\cite{goodrich:external}, and addition of several
application examples (examples of applications written using
TPIE can be found in the papers listed on the TPIE home
page). Another major project involves the addition of
support for random access to blocks as opposed to the stream
oriented access used in the current version of TPIE. This
addition will facilitate the implementation of indexing
structures (external data structures). Users interested in
obtaining/testing preliminary versions of these extensions
are encouraged to send a request to \verb|tpie@cs.duke.edu|.


\chapter{Obtaining and Installing TPIE}

\section{Licensing}

TPIE is available under the terms of the GNU General Public License,
\index{license} version 2.  A copy of this license appears in
Appendix~\ref{app:gpl}.

\section{Where to get TPIE}

The latest version of TPIE, \version, is an alpha test version.  It is
available through the \htmladdnormallink{TPIE WWW Home Page}{%
\begin{rawhtml}
http://www.cs.duke.edu/TPIE/
\end{rawhtml}%
}%
\begin{latexonly}
at URL \myverb{http://www.cs.duke.edu/TPIE/}.
\end{latexonly}
To obtain the TPIE source distribution\index{source distribution}, follow
the pointers from the home page to the distribution itself, which consists
of a gzipped tar file named {\tt tpie\_\version.tgz}. Your Web browser
should be capable of downloading this file to your local machine.


\section{Prerequisites}
\index{GNU software}
\plabel{sec:tut-gnu-software}

To uncompress and unarchive the distribution, you will need either the GNU
\myverb{tar} utility, or \myverb{gzip} and a \myverb{tar} program. (the GNU
version can decompress and untar at the same time with the '\myverb{z}'
option). The GNU \myverb{make} utility is also needed. This utility is
usually located in \myverb{/usr/local/bin/make} (or is called
\myverb{gmake}).
% \myverb{LaTeX} and associated tools are needed to generate the
%manual, and \myverb{latex2html} is required to generate the HTML version of
%the manual.

TPIE is heavily dependent on the compiler used, mainly
because of the use of C++ templates. It currently requires
the GNU C++ compiler, \myverb{gcc}, version~\gxxversion~ or
later (it has also been successfully compiled with
\myverb{gcc} version 2.7.2.1 on some systems). We are
currently using \myverb{gcc}, version~\gxxcurrent~ for most
development work on TPIE, and we expect that TPIE will also be
compatible with future version of this compiler. TPIE has
also been successfully compiled using \myverb{egcs}, version
2.91.66.

%In general, invoking the above utilities with the single command line
%argument \myverb{--version} will indicate whether they are compatible.
Information on how to obtain and install GNU software is
available at URL \\%
{\tt http://www.gnu.org/software/software.html}.


\section{Installation}\plabel{sec:tut-installation}
\index{installation}

%Once you have obtained the TPIE source distribution file
%{\tt tpie\_\version.tgz}, you must decide where to install it.
%\myverb{/usr/local/tpie/} is a typical place.

Place {\tt tpie\_\version.tgz} in the directory in which TPIE is to
be installed, \myverb{cd} into that directory, and execute the command

\begin{flushleft}
{\tt tar xzf tpie\_\version.tgz}
(or {\tt gunzip -c tpie\_\version.tgz | tar xvf -} )  
\end{flushleft}

This will produce a directory {\tt tpie\_\version} with
subdirectories \myverb{include}, \myverb{lib}, \myverb{lib/src},
\myverb{test}, and \myverb{doc}.  Enter the directory 
{\tt tpie\_\version}.  You must now configure TPIE for your
particular system.  To do this, use the command

\begin{verbatim}
./configure
\end{verbatim}

\index{configuration} Certain configuration options can be
specified to the {\tt configure} script, but usually these
will not be of interest the first time TPIE is installed.
These options are described in Section \ref{sec:customization}.

The configuration program will take some time to
examine the parameters of your system.  Once it has done so, it will
produce the various Makefiles and configuration files required to
build TPIE on your system.  When this is done, simply invoke your version
of GNU \myverb{make}:

\begin{verbatim}
make all
\end{verbatim}
to build the complete TPIE system.  This will build the
components of TPIE that must be tailored to your
system. This includes: the TPIE run-time library 
{\tt tpie\_\version/lib/libtpie.a}, the test and sample
programs in directory {\tt tpie\_\version/test}, 
and certain header files in {\tt tpie\_\version/include}.
You should now have a complete TPIE system, consisting of
the directories listed in Figure \ref{fig:components}.
\begin{figure}
\begin{center}
\begin{minipage}[hb]{1.0\linewidth}
\raggedright
\centering{
\begin{tabular}{|l|p{4in}|}
\hline
Directory & Contents \\
\hline
 \myverb{include}  & The TPIE header files.\index{header files}\\ 

 \myverb{lib}      & The TPIE run-time library.  This is relatively small, as most
                   of the TPIE system remains in the form of templated header
                   files.\index{library} \\
 \myverb{lib/src}  & The source code for the TPIE run-time
                   library. \\
 \myverb{test}     & A series of test applications designed to verify
                   that TPIE is operating correctly.  This
                   directory also includes the code for the
                   sample program discussed in Chapter
                   \ref{ch:samplepgmr}, and the example
                   applications described in
                   Appendix~\ref{ch:examples}.\index{test
                   applications}  \\
 \myverb{doc}      & Written documentation for TPIE,
                   consisting of the document you are
                   reading now, in DVI and Postscript(TM)
                   formats.\index{documentation} \\
\hline
\end{tabular}}
\caption{\plabel{fig:components} Components of the TPIE distribution.}
\end{minipage}
\end{center}
\end{figure}



\chapter{A Taste of TPIE via a Sample Program}
\plabel{ch:samplepgmr}

This chapter presents a quick look
at TPIE via a simple TPIE program. A more detailed TPIE
tutorial appears in Chapter \ref{ch:tutorial}. 

One of the primary themes in TPIE is to allow a user to
specify an I/O efficient computation via 
high-level coordination of data movement interspersed with
appropriate internal memory computing, with the low level I/O
details being transparent, or ``under the hood''.
TPIE provides various classes of ``management objects'',
(e.g. \emphd{scan management
   objects}, \emphd{merge management objects}, etc.) that
allow the user to specify sophisticated data movement
operations on \emphd{streams} of data in a simple and
straightforward manner. These management object classes are
built on top of a simple \emphd{stream interface} called
\myverb{AMI\_STREAM}. The tutorial in the next chapter explains
how to specify and use such management object classes.

%Using the sample example program below, we take a look at TPIE from a
%viewpoint just above the \myverb{AMI\_STREAM} interface.  
The sample program below uses simple stream
operations\comment{DH: %
   we use only STREAM member functions in the sample
   program, but never describe them in the tutorial. We
   should either describe them or illustrate the power of
   TPIE using operation management objects (scanning,
   merging, sorting, etc.} %
to generate a stream of random integers, scans this stream
of integers and partitions them into several distinct
streams. The manner in which I/O operations are handled by
TPIE ensures that the program is I/O efficient.

%Note that a 4-way distribution can easily be specified using an
%appropriately defined scan management object (see
%Section~\ref{sec:tut-scanning}), in which case the user does not have to use
%stream operations.

The intent of this example is to illustrate the sort of
things involved in TPIE programming; the typical include
files, specifying how much memory the program should use,
streaming operations, etc. The program is given in
Section~\ref{sec:tut-samplepgm} and it is discussed in
Section~\ref{sec:tut-samplepgm-discuss}.


\section{Sample Program}\plabel{sec:tut-samplepgm}
\index{sample program|(}
\index{sample program|)}

The following sample program can be found in {\tt
   tpie\_\version/test/sample\_pgm.cpp} after TPIE has been
   installed (see Section \ref{sec:tut-installation} of this manual for installation instructions).

\verbatiminput{sample_pgm.cpp}

\section{Discussion of Sample Program}\plabel{sec:tut-samplepgm-discuss}

In this section we discuss the simple simple C++ sample
program shown in the previous section. The file
\myverb{app\_config.h} is the TPIE configuration file. TPIE's
\myverb{AMI\_STREAM} stream I/O operations are carried out
transparently by one of three possible \emphd{block transfer
   engines (BTEs)}. Briefly, the file \myverb{app\_config.h} chooses
a specific BTE, and the amount of internal memory used as
buffer space for each \myverb{AMI\_STREAM}. The
\myverb{app\_config.h} configuration file is further discussed
in Section~\ref{sec:tuning} which also contains a discussion
of how to choose a BTE for a given platform. The file
\myverb{<ami.h>} contains TPIE's templated classes and
functions, while the file \myverb{<quicksort.h>} contains
various quicksort polymorphs. Note that each
\myverb{AMI\_STREAM} corresponds to an underlying Unix file.

The program illustrates the use of the basic
\myverb{AMI\_STREAM} member functions \myverb{read\_item()},
\myverb{write\_item()}, \myverb{seek()} and \myverb{persist()}.
Successful execution of these member functions is indicated
by a return value of \myverb{AMI\_ERROR\_NO\_ERROR}.  The program
distributes a randomly generated source stream of integers
into eight bucket streams, and then displays the time taken
by this operation and the size of each of the eight output
buckets. The randomly generated stream is deleted upon
completion of the program
(\myverb{source.persist(PERSIST\_DELETE)}), while the bucket
streams are saved (made persistent with
\myverb{buckets[i].persist(PERSIST\_PERSISTENT)}) in the
default scratch directory \myverb{/var/tmp}. The default
location for the scratch files can be changed by setting the environment variable
\myverb{AMI\_SINGLE\_DEVICE} appropriately (see
Section~\ref{sec:environment}).

TPIE can run with a user-specified amount of internal memory
(although typically, about 4MB is required as a minimum for
most simple applications) or it can run with virtual memory
like an ordinary non-TPIE application. The former mode is
invoked by calling \\%
\myverb{MM\_manager.ignore\_memory\_limit()}, and the latter
by calling \myverb{MM\_manager.enforce\_memory\_limit()}. In
the sample program, we call
\myverb{MM\_manager.enforce\_memory\_limit()}, which means
that the program will abort if the allocated internal memory
exceeds the specified amount. The call
\myverb{MM\_manager.set\_memory\_limit(test\_mm\_size)} tells
TPIE's internal memory manager \myverb{MM\_manager} to
prevent the program's internal memory usage from exceeding
\myverb{test\_mm\_size} bytes (note that
\myverb{test\_mm\_size} is the second input argument to our
program). When \myverb{MM\_manager.enforce\_memory\_limit()}
is used, it is the responsibility of the user to inform
\myverb{MM\_manager} via \myverb{set\_memory\_limit()} of the
desired memory limit.  For example, one might set this value
to the amount of physical main memory minus the main memory
used by the operating system and other programs running on
the machine.

%In the case of the present program, it is desirable to
%ensure that the program is allowed enough memory to comfortably accommodate
%the buffer space required by each one of the nine \myverb{AMI\_STREAM}s
%involved in the computation. The amount of buffer space required per
%\myverb{AMI\_STREAM} depends on the BTE implementation chosen in the
%\myverb{app\_config.h} file. Section~\ref{sec:env-variables} provides details
%of how to determine the buffer-space required for each BTE implementation.

The sample program can be compiled as follows:
(recall that Section \ref{sec:tut-gnu-software} discussed the version of GNU C++
required):

\begin{verbatim}
g++ sample_pgm.cpp -I../include/ -L../lib/ -ltpie -o sample_pgm
\end{verbatim}

By way of example, the program can be run with 1000000 random integers and 5000000 bytes of main
memory as follows:
\begin{verbatim}
sample_pgm 1000000 5000000
\end{verbatim}


\chapter{Tutorial}
\plabel{ch:tutorial}

\section{Introduction}\plabel{sec:tut-introduction}

This tutorial is designed to introduce new users to the TPIE system.
It introduces the fundamental paradigms of computation that TPIE
supports, giving source code examples of each.  The majority of the
code presented in the tutorial is available in the test
applications\index{test applications} directory of the distribution, 
{\tt tpie\_\version/test/}.

For the sake of brevity, much of the code presented in this tutorial is
incomplete, in the sense that necessary header files \index{header files}
and macros\index{macros} are omitted. Details concerning how to write your
own complete TPIE code is presented at the end of the tutorial in
Section~\ref{sec:tut-compiling} (see also Sections~\ref{ch:samplepgmr} and
\ref{sec:choosingbte})\comment{LA: Maybe we should talk briefly about AMI,
BTE, MM somewhere around here - we talk about main memory issues in merging
and compiling sections.}

TPIE is written in the C++ language, and this manual assumes
that the reader is familiar with C++.  If you would like to
use TPIE but are not familiar with the C++\index{C++}
language, a number of good books are available. If you are
familiar with C\index{C}, \cite{pohl:c++} is a good place to
start. A more basic, but very comprehensive book
is~\cite{deitel:c++}, and \cite{meyers:effective} is an
excellent source of information on intermediate and advanced
C++.  Finally, \cite{ellis:arm} is the definitive book on
C++, though not necessarily the best place for new
programmers to start.

Familiarity with the theoretical results on I/O-efficient
algorithms is not necessary in order to use TPIE. However,
this tutorial (and the rest of this manual) may be easier to
follow with some general background information such as how
a theoretically optimal external (merge) sort algorithm
works. Good references
are~\cite{vitter:podssurvey,arge:gisbook,aggarwal:input}.
Some of the basic concepts required for understanding the
discussion of I/O issues and external memory algorithms in
this manual are outlined in Section~\ref{sec:tut-concepts}.

\section{Basic Concepts}\plabel{sec:tut-concepts}
\index{concepts}\index{basic concepts}
\comment{Stuff there should maybe be something about: substreams,
persistence, read/write primitives, etc.} 
\comment{We start talking about memory
   constraints - there should be a general intro to blocks
   and stuff somewhere.}
   
Roughly speaking there is a factor of a million difference
in the access time of internal and external memory.  In
order to cope with the high cost of accessing
externally-stored data, efficient EM algorithms exploit
locality in their design.  They access a large \emphd{block}
of $B$ contiguous data elements at a time and perform the
necessary algorithmic steps on the elements in the block
while it is in the high-speed memory. The speedup can be
considerable.  A second effective strategy for EM algorithms
is the use of multiple parallel disks; whenever an
input/output operation is performed, $D$ blocks are
transferred in parallel between memory and each of the $D$
disks (one block per disk).

The performance of an EM algorithm on a given set of data is
affected directly by how much internal memory is available
for its use. We use $M$ to denote the number of application
data elements that fit into the internal memory available to
the algorithm, and $m=M/B$ denotes the number of blocks that
fit into the available internal memory. Such a block is more precisely
called a \emphd{logical block} because it may be a different
size (usually larger) than either the physical block size or
the system block size. We will reserve the term
\emphd{physical block} size to mean the 
block size used by a disk controller to communicate with
a physical disk, and the \emphd{system block} size will be the
size of block used within the operating system for I/O
operations on disk devices. In EM algorithms we will assume
that the logical block size is a multiple of the system
block size. In TPIE, for instance, this factor is currently
set to 32 if not changed by the user.

TPIE is implemented as a set of templated classes and
functions in C++, and employs an object-oriented abstraction
to EM computation. TPIE provides C++ templates of various
optimal EM computation \emphd{patterns} or \emphd{paradigms}.
Examples of such paradigms are the EM algorithms for merge
sorting, distribution sweeping, time forward processing,
etc. (see \cite{vitter:dimacssurvey}). In a TPIE program, the
application programmer provides application-specific details
of the specific computation paradigm used, such as C++
object definitions of the application data records, and code
for application-specific sub-computations at critical points
in the computation pattern, but TPIE provides the
application-independent parts of the pattern.  

The definition of an application data element (or record) is
provided by the user as a class definition.  Such a class
definition is typically used as a template parameter in a
TPIE code fragment (e.g. a templated function). Other
template parameters may be instantiated by choices the user
makes between algorithm options (e.g. between sorting
variants) or between operating system interfaces (e.g. the
choice of BTE) for instance. These user selections allow a
pattern replesented by a templated C++ code fragment to be
instantiated as an actual piece of executable code, tailored
to the data types required by the user's application.

Application-dependent sub-computations (e.g. a comparison
function used to determine the order of two application data
elements during a sort) are typically structured as methods
of an \emphd{operation management object}. TPIE dictates the
names and required functionality of each method of an
operation management object, but the details of the
computation performed by a specific method are
application-specific and thus are the responsibility of the
application programmer. 


\section{Streams}\plabel{sec:tut-streams}
\index{stream}\index{structure!of streams}
\comment{LA: Stuff there should maybe be something about: substreams,
persistence, read/write primitives, ect. DH: See above.}


In TPIE, a \emphd{stream} is an ordered collection of objects
of a particular type, stored in external memory, and
accessed in sequential order. Streams can be thought of as
fundamental TPIE objects which map volatile, typed
application data elements in internal
memory to persistent, untyped data elements in external
memory, and vice-versa.  Streams are read and written like
files in Unix and support a number of primitive file-like
operations such as read(), write(), truncate(), etc. 
%See Section \ref{implementationofstreams} for more
%information.
TPIE also supports the concept of a \emphd{substream}, which
permits a contiguous subset of the elements in a stream to
accessed sequentially. Multiple substreams can be created on
streams and even on other substreams. 
%Substreams are deprecated in TPIE due to performance issues
%(see Section \ref{substreams} for more information).

Various paradigms of external memory computation are
supported on streams (and substreams) in TPIE, including
scanning (see Section \ref{sec:tut-scanning}), merging (see
Section \ref{sec:tut-merging}), and sorting (see Section
\ref{sec:tut-sorting}). TPIE reduces the programming effort
required to perform an external sort, merge, etc., by
providing the high level flow of control within each
paradigm, and therefore structuring this part of the
computation so that it will be I/O efficient. The programmer
is left with the task of providing what amount to ``event
handlers'', specifying the application-specific details of
the computation. For instance in sorting, the programmer
defines a stream of input data, a comparison function (the
event handler for the task of comparing two application data
elements), and an output stream for the results. In TPIE
terminology, the collection of necessary event handlers for
a particular EM computational paradigm is contained in an
\emphd{operation management object}. Operation management objects differ
according to which paradigm is used.  See Section
\ref{sec:tut-scanning} for a discussion of scan management
objects, Section \ref{sec:tut-merging} for a discussion of merge
management objects, and Section \ref{sec:tut-sorting} for a
discussion of sort management objects.

Creating a stream of objects in TPIE is very much like
creating any other object in C++. The only difference is
that the data placed in the stream is stored in external
memory (on disk). 
%In some respects this aspect of TPIE can
%be viewed as an implementation of \emphd{persistent objects}
%(see Section~\ref{BCCstuff} for more discussion of persistent objects).
For example, to create an (empty) stream \myverb{stream0}
capable of storing integers, we could use the following:
\begin{verbatim}
AMI_STREAM<int> stream0;
\end{verbatim}
Alternatively, the following creates a pointer
\myverb{p} to an empty stream of \myverb{applrec} objects:
\begin{verbatim}
AMI_STREAM<applrec> *p = new AMI_STREAM<applrec>;
\end{verbatim}

The {\tt AMI} prefix in {\tt AMI\_STREAM} stands for
\emphd{Access Method Interface}\index{Access Method Interface
   (AMI)}\index{AMI}. This layer of TPIE contains the
services and functionality which a normal user of TPIE will
require.  {\tt AMI\_STREAM} is actually a compile-time macro
that evaluates to the name of a particular implementation of
streams, but for now it is safe to assume that it is simply
a C++ class.

The {\tt AMI\_STREAM} constructor does not actually put
anything into the stream; it simply creates the necessary
data structures to keep track of the contents of the stream
when data is actually put into it.  One basic way of putting
data into a stream is via \myverb{AMI\_scan()}, which is
described in Section \ref{sec:tut-scanning}.

\section{Operation Management Objects} 
\plabel{sec:tut-omos}\index{operation management object}

TPIE provides a structure for performing a number of basic
operations, such as scanning a stream of items, merging
streams of items, sorting a stream of items, etc. Much of
the application-independent work in these operations is
handled by TPIE. The TPIE user, however, must provide the
code for the application-dependent aspects of these
operations via a TPIE {\em operation management object}. An
operation management object in TPIE is an object which
contains member functions to control the critical,
application-varying aspects of operations such as scanning,
merging, and sorting. TPIE expects certain named methods of
the object to be present, depending on the operation being
performed. 

The operation management object for scanning (called a
``scan management object''\index{operation management
   object!scan}), for instance, must provide methods {\em
   initialize} (for initializing any user-required data
structures of the scan), and {\em operate} (for performing
whatever steps are needed as each data item is encountered
in the scan). See Section \ref{sec:tut-scanning} below for more
information.

In the example of merging, the rules for ``combining''
elements of the merge operation are necessarily application
dependent. TPIE expects a ``merge management
object''\index{operation management object!merge} to contain
members \myverb{initialize} and \myverb{operate}, as well as
several others. Detailed requirements for merge management
objects are described in Section \ref{sec:tut-merging}.

\section{Scanning}
\plabel{sec:tut-scanning}

\index{scanning|(} \index{AMI_scan()@{\tt AMI\_scan()}}
The simplest paradigm available in TPIE is scanning.  Scanning can be
used to produce streams, examine the contents of streams, or transform
streams.  

\subsection{Basic Scanning}

One basic thing a scan can do is write a series of
objects to a stream.  In the following example, we create a
stream of integers consisting of the first 10000 natural
numbers.  

\begin{verbatim}
class scan_count : AMI_scan_object {
private:
    int maximum;
    int nextint;
public:
    scan_count(int max) : maximum(max), ii(0) {};

    AMI_err initialize(void) 
    {
        nextint = 0;
        return AMI_ERROR_NO_ERROR;
    };

    AMI_err operate(int *out1, AMI_SCAN_FLAG *sf)
    {
        *out1 = ++nextint;
        return (*sf = (nextint <= maximum)) ? AMI_SCAN_CONTINUE : 
            AMI_SCAN_DONE;
    };
};

scan_count sc(10000);
AMI_STREAM<int> amis0;    

void f()
{
    AMI_scan(&sc, &amis0);
}
\end{verbatim}

The object \myverb{sc} is called a scan management
object\index{operation management object!scan}.  It has two
member functions, \myverb{initialize()} and
\myverb{operate()}, which TPIE calls when asked to perform a
scan.  The first member function, \myverb{initialize()} is
called at the beginning of the scan.  TPIE expects that a
call to this member function will cause the object to
initialize any internal state it may maintain in preparation
for performing a scan.  The second member function,
\myverb{operate()}, is called repeatedly during the scan to
create objects to go into the output stream.
\myverb{operate()} sets the flag \myverb{*sf} to indicate
whether it generated output or not.  TPIE will call
\myverb{operate()} as long as \myverb{operate()} returns
\myverb{AMI\_SCAN\_CONTINUE}. The normal way for
\myverb{operate()} to signal that it is finished is to
return the value \myverb{AMI\_SCAN\_DONE}. 

\myverb{AMI\_scan} behaves as the following pseudo-code:

\begin{verbatim} 
AMI_err AMI_scan(scan_count &sc, AMI_STREAM<int> *pamis)
{
    int nextint;
    AMI_err ae;    
    AMI_SCAN_FLAG sf;

    sc.initialize();    
    while ((ae = sc.operate(&nextint, &sf)) == AMI_SCAN_CONTINUE) {
        if (sf) {
            Write nextint to *pamis;
        }
    }

    if (ae != AMI_SCAN_DONE) {
        Handle error conditions;
    }

    return AMI_ERROR_NO_ERROR;
}
\end{verbatim}

Thus, after the function \myverb{f()} in the original
example code returns, the stream \myverb{amis0} will contain
the integers from 1 to 10000 in increasing order.

One of the simplest things we can do with a stream of
objects is scan it in order to transform it in some way.  As
an example, suppose we wanted to square every integer in the
stream \myverb{amis0}.  We could do so using the following
code:

\begin{verbatim}
class scan_square : AMI_scan_object {
public:
    AMI_err initialize(void)
    {
        return AMI_ERROR_NO_ERROR;
    };

    AMI_err operate(const int &in, AMI_SCAN_FLAG *sfin,
                    int *out, AMI_SCAN_FLAG *sfout)
    {
        if (*sfout = *sfin) {
            *out = in * in;
            return AMI_SCAN_CONTINUE;
        } else {
            return AMI_SCAN_DONE;
        }
    };
};

scan_square ss;
AMI_STREAM<int> amis1;    

void g() 
{
    AMI_scan(&amis0, &ss, &amis1);
}
\end{verbatim}

Notice that the call to \myverb{AMI\_scan()} in \myverb{g()}
differs from the one we used in \myverb{f()} in that it
takes two stream pointers and a scan management object.  By
convention, the stream \myverb{amis0} is an input stream,
because it appears before the scan management object
\myverb{ss} in the argument list.  By similar convention,
\myverb{amis1} is an output stream.  Because the call to
\myverb{AMI\_scan} has one input stream and one output
stream, TPIE expects the \myverb{operate()} member function
of \myverb{ss} to have one input argument (which is called
\myverb{in} in the example above) and one output argument
(called \myverb{out} in the example above).  Note that the
\myverb{operate()} member function of the class
\myverb{square\_scan} also takes two pointers to flags, one
for input (\myverb{sfin}) and one for output
(\myverb{sfout}).  \myverb{*sfin} is set by TPIE to indicate
that there is more input to be processed.  \myverb{*sfout}
is set by the scan management object to indicate when output
is generated.  A scan management object must contain an
\myverb{operate()} member function that takes the
appropriate types and number of arguments for the invocation
of \myverb{AMI\_scan()} that uses it, or else a compile-time
error will be generated.

\myverb{AMI\_scan} with one input stream and one output stream
behaves as the following pseudo-code:

\begin{verbatim} 
AMI_err AMI_scan(AMI_STREAM<int> *instream, scan_square &ss, 
        AMI_STREAM<int> *outstream)
{
    int in, out;
    AMI_err ae;    
    AMI_SCAN_FLAG sfin, sfout;

    sc.initialize();

    while (1) {
        {
             Read in from *instream;
             sfin = (read succeeded);
        }
        if ((ae = ss.operate(in, &sfin, &out, &sf)) == 
            AMI_SCAN_CONTINUE) {
            if (sfout) {
                Write out to *outstream;
            }
            if (ae == AMI_SCAN_DONE) {
                return AMI_ERROR_NO_ERROR;
            }
            if (ae != AMI_SCAN_CONTINUE) {
                Handle error conditions;
            }
        }
    }
}
\end{verbatim}

\myverb{AMI\_scan()} can operate on up to four input streams
and four output streams.  Here is an example that takes two
input streams of values, \myverb{x} and \myverb{y}, and
produces four output streams, one consisting of the running
sum of the \myverb{x} values, one consisting of the running
sum of the \myverb{y} values, one consisting of the running
sum of the squares of the \myverb{x} values, and one
consisting of the running sum of the squares of the
\myverb{y} values.

\begin{verbatim}
class scan_sum : AMI_scan_object {
private:
    double sumx, sumx2, sumy, sumy2;
public:
    AMI_err initialize(void)
    {
        sumx = sumy = sumx2 = sumy2 = 0.0;
        return AMI_ERROR_NO_ERROR;
    };

    AMI_err operate(const double &x, const double &y, 
                    AMI_SCAN_FLAG *sfin,
                    double *sx, double *sy, 
                    double *sx2, double *sy2, 
                    AMI_SCAN_FLAG *sfout)
    {
        if (sfout[0] = sfout[2] = sfin[0]) {
            *sx = (sumx += x);
            *sx2 = (sumx2 += x * x);
        }
        if (sfout[1] = sfout[3] = sfin[1]) {
            *sy = (sumx += y);
            *sy2 = (sumy2 += y * y);
        }        
        return (sfin[0] || sfin[1]) ? AMI_SCAN_CONTINUE : AMI_SCAN_DONE;
    };
};

AMI_STREAM<double> xstream, ystream;

AMI_STREAM<double> sum_xstream, sum_ystream, sum_x2stream, sum_y2stream;

scan_sum ss;

void h()
{
    AMI_scan(&xstream, &ystream, &ss, 
             &sum_xstream, &sum_ystream, &sum_x2stream, &sum_y2stream);
}
\end{verbatim}
\comment{DH: should we summarize what polymorphs are
   available or give a pointer to the section that does?}

\subsection{ASCII Input/Output} \plabel{sec:tut-ascii-io}

\index{ASCII I/O|see{scanning, ASCII I/O}}
\index{scanning!ASCII I/O|(}
TPIE provides a number of predefined scan management objects.  Among
the most useful are instances of the template classes
\myverb{cxx\_ostream\_scan<T>} and \myverb{cxx\_ostream\_scan<T>}, which are
used for reading ASCII data into streams and writing the contents of
streams in ASCII respectively.  This is done in conjunction with the
\myverb{iostream} facilities provided in the standard C++ library.  Any
class \myverb{T} for which the operators \myverb{ostream
\&operator<<(ostream \&s, T \&t)} and \myverb{istream \&operator>>(T \&t)}
are defined can be used with this mechanism.

As an example, suppose we have an ASCII file called \myverb{input\_nums.txt}
containing one integer per line, such as

\begin{verbatim}
17
289
4195835
3145727
.
.
.
\end{verbatim}

The following code copies this file into a TPIE stream of
integers, squares each one, and
writes the results to the file \myverb{output\_nums.txt}.

\begin{verbatim}
void f()
{
    ifstream in_ascii("input_nums.txt");
    ofstream out_ascii("output_nums.txt");
    cxx_istream_scan<int> in_scan(in_ascii);
    cxx_ostream_scan<int> out_scan(out_ascii);
    AMI_STREAM<int> in_ami, out_ami;
    scan_square ss;    

    // Read them.
    AMI_scan(&in_scan, &in_ami);

    // Square them.
    AMI_scan(&in_ami, &ss, &out_scan);
    
    // Write them.
    AMI_scan(&out_ami, out_scan);

}    
\end{verbatim}

In order to read from an ASCII input file using the scan
management object \myverb{in\_scan}, \myverb{AMI\_scan()}
repeatedly calls \myverb{in\_scan->operate()}, just as it
would for any scan management object.  Each time
\myverb{in\_scan->operate()} is called, it uses the
\myverb{>>} operator to read a single integer from the input
file.  When the input file is exhausted,
\myverb{in\_scan->operate()} returns
\myverb{AMI\_SCAN\_DONE}, and \myverb{AMI\_scan()} returns
to its caller.  The behavior of \myverb{out\_scan} is
similar to that of \myverb{in\_scan}, except that it writes
to a file instead of reading from one.
\index{scanning!ASCII I/O|)}

\subsection{Multi-Type Scanning}

\index{scanning!multi-type|(}

In all of the examples presented up to this point, scanning
has been done on streams of objects that are all of the same
type.  \myverb{AMI\_scan()} is not limited to such scans,
however.  In the following example, we have a scan
management class that takes two streams of \myverb{double}s
and returns a stream of complex numbers.

\begin{verbatim}
class complex {
public:
    complex(double real_part, imaginary_part);
    ...
};

class scan_build_complex : AMI_scan_object {
public:
    AMI_err initialize(void) {};
    AMI_err operate(const double &r, const double &i, 
                    AMI_SCAN_FLAG *sfin,
                    complex *out, AMI_SCAN_FLAG *sfout)
    {
        if (*sfout = (sfin[0] || sfin[1])) {
            *out = complex((sfin[0] ? r : 0.0), (sfin[1] ? i : 0.0));
            return AMI_SCAN_CONTINUE;
        } else {
            return AMI_SCAN_DONE;
        }   
    };
};
\end{verbatim}
\index{scanning!multi-type|)}

\subsection{Out of Step Scanning}
\plabel{sec:tut-out-of-step}

\index{scanning!out of step|(}
In all the examples up to this point, the
\myverb{operate()} member function of a scan management object has been
called exactly once for each object in the input stream(s).  In this
section, we discuss the concept of out of step scanning,
which involves using a scan management object to reject certain inputs and ask that
they be resubmitted in subsequent calls to the \myverb{operate()} member
function.

Suppose we have two streams of integers, each of which is
sorted in ascending order.  We would like to merge the two streams
into a single output stream consisting of all the integers in the two
input streams, in sorted order.  In order to do this with a scan, we
must have the ability to look at the next integer from each stream,
choose the smaller of the two and write it to the output stream, and
then ask for the next number from the stream from which it was taken.
There is a simple mechanism for doing this.  The same flags
that TPIE uses to tell the scan management object which inputs are
available can also be used by the scan management object to indicate which
inputs were used (i.e. ``consumed'') and which should be presented again.

Consider the following example of a scan management object class which
performs this sort of binary
merge\index{merge!binary}\index{merge sort!binary}:

\begin{verbatim}
class scan_binary_merge : AMI_scan_object {
public:
    AMI_err initialize(void) {};
    
    AMI_err operate(const int &in0, const int &in1, AMI_SCAN_FLAG *sfin,
                    int *out, AMI_SCAN_FLAG *sfout) 
    {
        if (sfin[0] && sfin[1]) {
            if (in0 < in1) {
                sfin[1] = false;
                *out = in0;
            } else {
                sfin[0] = false;
                *out = in1;
            }
        } else if (!sfin[0]) {
            if (!sfin[1]) {
                *sfout = false;
                return AMI_SCAN_DONE;
            } else {
                *out = in1;
            }
        } else {
            *out = in0;
        }
        *sfout = 1;
        return AMI_SCAN_CONTINUE;
    }
};
\end{verbatim}

In the operate method, we first check that both inputs are valid by
looking at the flags pointed to by \myverb{sfin}.  If both are valid,
then we select the smaller of the inputs and copy it to the output.
We then clear the other input flag to let TPIE know that we did not
use that input, but we will need it later and it should be resubmitted
on the next call to operate. The remainder of the function handles
the cases when one of more of the input streams are empty.
\index{scanning!out of step|)}
\index{scanning|)}


\section{Merging} \plabel{sec:tut-merging}
\index{merging|(}

While \myverb{AMI\_scan()} is limited to operate on up to
four input and four output streams, theoretically efficient
external memory algorithms often operate on eight or more
streams, the exact number depending on the amount of
internal memory available. An especially common operation is
merging of a large number of input streams into one output
stream.\footnote{Note that ``merge'' here means the process
   of reading the content of a number of input streams in
   some interleaved order producing an output stream.
   Merging a number of sorted input streams into a sorted
   output stream is a special (but common) case of
   merging.} An example of the this is external merge
sorting. The \myverb{scan\_binary\_merge} scan management
object presented in the previous section could be used
recursively to implement a merge sorting\index{merge
   sorting!binary} algorithm. We could simply divide the
input stream into sub-streams small enough to fit into main
memory, read each sub-stream into memory and sort it, and
then merge pairs of streams, then pairs of merged pairs of
streams, and so on, until we had merged all the input back
into one completely sorted stream. While this approach would
correctly sort the input, it would not be nearly as
efficient as possible on most machines. The reason is that
we typically have enough main memory available to merge many
more streams together at one time~\cite{aggarwal:input}.

TPIE therefore provides the function \myverb{AMI\_merge()}
which, depending on the main memory available, merges a
variable number of input streams into an output stream in a
single scan of the input streams. As in the case of
\myverb{AMI\_scan}, the application-specific details of how the merge
is performed are specified via an operation management
object (in this case, a  merge management object)
with member functions \myverb{initialize()} and
\myverb{operate()}.\comment{LA: The AMI\_merge stuff should
   be rewritten with some examples}\footnote{%
   \myverb{ami\_merge} also has three specialized polymorphs
   for merging according to a total order on the data
   elements. These specialized polymorphs do not use a merge
   management object. Refer to
   Section~\ref{sec:ref-ami-merge}.} 
However, often, as in the merge sort example, one wants to
merge more streams than memory constraints allow in a single
pass, and so the merge may have to be done in several recursive
stages.
\comment{LA: Here we start talking about memory
   constraints - there should be a general intro to blocks
   and stuff somewhere.} 
Since it can be cumbersome to compute precisely how
many streams can be merged in one pass --- one must keep
track of the space needed for input blocks from each of the
streams being merged, as well as the overhead of any data
structures needed for the merge --- TPIE provides a
mechanism that does most of this work for us. The
function \myverb{AMI\_partition\_and\_merge()} divides an
input stream into sub-streams just small enough to fit into
main memory, operates on each in main memory, then merges
them back into a single output stream, using intermediate
streams if memory constraints dictate. As in the case of
\myverb{AMI\_merge()}, the functional details of
\myverb{AMI\_partition\_and\_merge()} are specified via a
merge management object. In fact the merge management object
for \myverb{AMI\_merge()} is a special case of the one for
\myverb{AMI\_partition\_and\_merge()}. The following example
illustrates the use of \myverb{AMI\_partition\_and\_merge()}:

\begin{verbatim}
class my_merger : AMI_merge_base {
public:
    AMI_err initialize(arity_t arity, const T * const *in,
                       AMI_merge_flag *taken_flags,
                       int &taken_index);
    AMI_err operate(const T * const *in, AMI_merge_flag *taken_flags,
                    int &taken_index, T *out);
    AMI_err main_mem_operate(T* mm_stream, size_t len);
    size_t space_usage_overhead(void);
    size_t space_usage_per_stream(void);
};

AMI_STREAM<T> instream, outstream;

void f() 
{
    my_merger mm;    
    AMI_partition_and_merge(&instream, &outstream, &mm);
}
\end{verbatim}

The member functions of the merge management object
\myverb{mm} are as follows:

\begin{description}
    \item[\myverb{initialize()}] Tells the object how many
    streams TPIE has chosen to (\myverb{arity}) and what the
    first item from each stream is (\myverb{in}). The
    variables \myverb{taken\_flags} and
    \myverb{taken\_index} provide two mechanisms for the
    merge manager to tell TPIE what objects it took from the
    input streams. These are discussed in more detail in the
    context of a merge sorting example in
    Section~\ref{sec:tut-mergesort}.
    \item[\myverb{operate()}] Just as in scanning, this
    member function is called repeatedly to process input
    objects.
    \item[\myverb{main\_mem\_operate()}] Called by TPIE to
    operate on an array of data in main memory.
    \item[\myverb{space\_usage\_overhead()}] Called by TPIE
    prior to initialization to assess how much main memory
    this object will use.
    \item[\myverb{space\_usage\_per\_item()}] Called by TPIE
    prior to initialization to assess how much main memory
    may be used per input stream. Merge management objects
    are allowed to use main memory space linear in the
    number of input streams.
\end{description}

The following pseudo-code describes the operation of
\myverb{AMI\_partition\_and\_merge()}.  Note that for
simplicity of presentation, boundary conditions are not
covered.

\begin{verbatim}
AMI_err AMI_partition_and_merge(instream, outstream, mm)
{
    max_ss = max # of items that can fit in main memory;
    Partition instream into num_substreams substreams of size max_ss;

    Foreach substream[i] {
        Read substream[i] into main memory;
        mm->main_mem_operate(substream[i]);
        Write substream[i];
    }

    Call mm->space_usage_overhead() and mm->space_usage_per_stream;
    
    Compute merge_arity; // Maximum # of streams we can merge.     

    while (num_substreams > 1) {
        for (i = 0; i < num_substreams; i += merge_arity) {
            Merge substream[i] .. substream[i+merge_arity-1];
        }
        num_substreams /= merge_arity;
        max_ss *= merge_arity;
    }

    Write single remaining substream to outstream;
        
    return AMI_ERROR_NO_ERROR;
}
\end{verbatim}


\subsection{Implementing Mergesort: An Extended Example}
\plabel{sec:tut-mergesort}

In the following we give an example of the implementation and
use of a merge management object for merge sorting integers.
We use merge sorting as a non-trivial example to illustrate
the interfaces and mechanisms involved in using a merge
management object. However, the reader should refer to
Section \ref{sec:tut-sorting} on sorting for a more
straightforward and efficient way to sort with TPIE.

First, we declare the class:

\comment{LA: We should probably change AMI\_merge\_base to AMI\_merge\_object at some point}

\begin{verbatim}
class MergeMgr : public AMI_merge_base<int> { 
private:
    arity_t input_arity;
    pqueue  *pq;
public:
    MergeMgr (void);
    virtual ~MergeMgr  (void);
    AMI_err initialize (arity_t arity, const int * const *in,
                       AMI_merge_flag *taken_flags, int &taken_index);
    AMI_err operate    (const int * const *in, AMI_merge_flag *taken_flags,
                       int &taken_index, int *out);
    AMI_err main_mem_operate      (int* mm_stream, size_t len);
    size_t  space_usage_overhead  (void);
    size_t  space_usage_per_stream(void);
};
\end{verbatim}

In addition to the standard class members for a merge management
object, we have the following:

\begin{description}
    \item[\myverb{input\_arity}] The number of input streams
    the merge management object must handle.
    \item[\myverb{pq}] A priority queue into which items
    will be placed.
    \item[\myverb{MergeMgr()}] A constructor.
    \item[\myverb{\~{}MergeMgr()}] A destructor.
\end{description}

Construction and destruction are fairly straightforward.  At construction
time, we have no priority queue because we do not yet know how big the
priority queue should be.  \myverb{pq} will be set up when \myverb{initialize}
is called.  The destructor checks whether
\myverb{pq} is valid, and deletes it if it is.  The constructor and
destructor are implemented as follows:

\begin{verbatim}
MergeMgr::MergeMgr(void)
{
    pq = NULL;
}

MergeMgr::~MergeMgr(void)
{
    if (pq != NULL) {
        delete pq;
    }
}
\end{verbatim}

When \myverb{AMI\_partition\_and\_merge()} is invoked 
it calls the member functions \\%
\myverb{space\_usage\_overhead()} and
\myverb{space\_usage\_per\_stream()} of the merge management
object (\myverb{MergeMgr} in this case).  These
return the number of bytes of main memory that the merge
management object will allocate when initialized.  In our
example, the return value from
\myverb{space\_usage\_overhead()} indicates that space will
needed for a priority queue, and the return value from
\myverb{space\_usage\_per\_stream()} indicates that space
%for each input stream, space (which is to be allocated
%when the priority queue is constructed) 
will be needed for an object of type \myverb{int} and one of
type \myverb{arity} associated with each stream.

\begin{verbatim}
size_t MergeMgr::space_usage_overhead(void)
{
    return sizeof(pqueue<arity_t,int>);
}


size_t MergeMgr::space_usage_per_stream(void)
{
    return sizeof(arity_t) + sizeof(int);
}
\end{verbatim}

As an early step in its processing,
\myverb{AMI\_partition\_and\_merge()} will divide the input
stream into ``memoryloads'' (which fit into main
memory). It then calls the member function
\myverb{main\_mem\_operate()} of the merge management object
to perform application specific processing on these memoryloads.
Since we are sorting in this example, we simply sort each memoryload
via quicksort. The sorted memoryloads are then stored on the
disks as substreams.

\begin{verbatim}
AMI_err MergeMgr::main_mem_operate(int* mm_stream, size_t len)
{
    qsort(mm_stream, len, sizeof(int), c_int_cmp);
    return AMI_ERROR_NO_ERROR;
}
\end{verbatim}

Having sorted all of the initial substreams,
\myverb{AMI\_partition\_and\_merge()} begins to merge them.
Before merging a set of substreams, the merge management
object's member function \myverb{initialize()} is called to
inform the merge management object of the number of streams
it should be prepared to handle at the merge step.  The
object is also provided with the first object from each of
the streams to be merged.  In our example the
\myverb{initialize()} member function is as follows:

\begin{verbatim}
AMI_err MergeMgr::initialize(arity_t arity, const int * const *in,
                                    AMI_merge_flag *taken_flags,
                                    int &taken_index)
{
    input_arity = arity;

    if (pq != NULL) {
        delete pq;
    }

    // Construct a priority queue that can hold arity items.
    pq = new pqueue_heap_op(arity);

    for (arity_t ii = arity; ii--; ) {
        if (in[ii] != NULL) {
            taken_flags[ii] = 1;
            pq->insert(ii,*in[ii]);
        } else {
            taken_flags[ii] = 0;
        }
    }

    taken_index = -1;
    return AMI_MERGE_READ_MULTIPLE;
}
\end{verbatim}

Note the use of the return value \myverb{AMI\_MERGE\_READ\_MULTIPLE}.  This
indicates that the flags in \myverb{*taken\_flags} are set to
indicate which of the inputs were used (and should not be presented
again).  This is very similar to the use of input flags to indicate
which inputs were used by a scan management object as described in
Section~\ref{sec:tut-out-of-step}.  The reason that we have a special
return value to indicate when these flags are used is to increase
performance.  In order for \myverb{AMI\_scan()} to determine which inputs
were taken, it must examine all the flags.  In a many way merge, this
might be time consuming.  In cases where only one item is taken, its
index can be returned in \myverb{taken\_index} in order to save the time
that would be spent scanning the flags.  This technique is illustrated in our
\myverb{operate()} member function, below.

\begin{verbatim}
AMI_err MergeMgr::operate(const int * const *in,
                                 AMI_merge_flag *taken_flags,
                                 int &taken_index,
                                 int *out)
{
    // If the queue is empty, we are done.  There should be no more
    // inputs.
    if (!pq->num_elts()) {
        return AMI_MERGE_DONE;
    } else {
        arity_t min_source;
        int min_t;

        pq->extract_min(min_source,min_t);
        *out = min_t;
        if (in[min_source] != NULL) {
            pq->insert(min_source,*in[min_source]);
            taken_index = min_source;
        } else {
            taken_index = -1;
        }
        return AMI_MERGE_OUTPUT;
    }
}
\end{verbatim}
\index{merging|)}

\comment{LA: Something here?}

\section{Distribution} \plabel{sec:tut-distribution}
\index{Distribution}

\tobewritten

\comment{LA: We should look at the kb\_sort stuff and get it cleaned-up/done}

%Distribution has not been implemented in the current version of TPIE.
%It is primarily useful for parallel disks, and will be implemented in
%the parallel disk version of TPIE.  On a single disk, merging should
%be adequate for all applications where distribution might be
%considered.
%
%On a single disk, distribution will tend to result in algorithms that
%take roughly twice as long as similar algorithms that use merging.
%This is because distribution is done to the square root of the number
%of streams that can be buffered in main memory rather than the full
%number.  This results in recursion that is twice as deep.


\section{Sorting}
\label{sec:tut-sorting}
\subsection{Comparison Sorting} \plabel{sec:tut-cmp-sorting}

\index{sorting!comparison|(} 
Sorting is a common primitive operation in many algorithms.
It can be performed in a variety of ways. The two most basic
approaches for external memory sorting are based on merging
(See Section~\ref{sec:tut-merging}), and distribution (See
Section~\ref{sec:tut-distribution}).
%, or Sharesort~\cite{aggarwal:optimal}. The
%latter combines elements of both, along with simple bit permutations
%(See Section~\ref{sec:tut-bit-permuting}). 
TPIE currently provides several efficient sorting functions
based on merging.  In the future a number of other sorting
algorithms may be implemented and it is the intention that
when calling \myverb{AMI\_sort()}, TPIE should automatically
select the best algorithm for the given hardware platform.

\subsection{Merge Sorting} \plabel{sec:tut-mrg-sorting}
\index{sorting!merge|(} 
While the \myverb{AMI\_merge} example in
Section~\ref{sec:tut-merging} was not intended as an
illustration of how to sort in TPIE, it contains the main
ideas of how merge sorting should be done in order to
achieve I/O optimality, and how it is done internally by
TPIE's merge sort services.

\noindent
\emphd{Merge sort} consists of two phases: the run formation
phase and the merging phase.  During the \emphd{run formation
   phase}, the $N$ input elements are input $M$ (one \emphd{memory-load})
at a time; each memory-load is sorted and written to the
disks as a ``run''.  In the \emphd{merge phase}, the sorted
runs are merged together approximately $M/B$ at a time (where $M$
is the internal memory size and $B$ is the block size) in a
round-robin manner until a single sorted run remains.
Typically, a heap or similar data structure is used during
the merge phase to select the next record to be output from
the set of records presented by the sorted runs being
merged. 

Currently, TPIE offers three merge sorting variants. The
user must decide which variant is most appropriate for their
circumstances.  All accomplish the same goal, but the
performance can vary depending on the situation. They differ
mainly in the way they perform the merge phase of merge
sort, specifically how they maintain their heap data
structure used in the merge phase. The three variants are as
follows:
\begin{itemize}
    \item \myverb{AMI\_sort}: keeps the (entire) first record
    of each sorted run (each is a stream) in a heap. This
    approach is most suitable when the record consists
    entirely of the record key.
    
    \item \myverb{AMI\_ptr\_sort}: keeps a pointer to the
    first record of each stream in the heap. This approach
    works best when records are very long and the key
    field(s) take up a large percentage of the record.

    \item \myverb{AMI\_key\_sort}: keeps the key field(s) and
    a pointer to the first record of each stream in the
    heap. This approach works best when the key field(s) are
    small in comparison to the record size.
\end{itemize}

Any of these variants will accomplish the task of sorting an
input stream in an I/O efficient way, but there can be
noticeable differences in processing time between the
variants. As an example, \myverb{AMI\_key\_sort} appears to be
more cache-efficient than the others in many cases, and
therefore often uses less processor time, despite extra data
movement relative to \myverb{AMI\_ptr\_sort}.

In addition to the three variants discussed above, there are
multiple choices within each variant regarding how the
actual comparison operations are to be performed. These
choices are described in detail for \myverb{AMI\_sort}, below.
%Because the best choice of sorting
%algorithm varies from one I/O system to the next, TPIE provides a single
%function \myverb{AMI\_sort()}, which selects an appropriate algorithm based on
%the underlying hardware characteristics.

\subsubsection{AMI\_sort()}
\myverb{AMI\_sort()} has three polymorphs, described below.
We will refer to these as the (1) comparison operator, (2)
comparison function, and (3) comparison object versions of
\myverb{AMI\_sort}. The comparison operator version tends to
be the fastest and most straightforward to use. The
comparison object version is comparable in speed (maybe
slightly slower), but somewhat more flexible, as it can support
multiple, different sorts on the same keys. The comparison
function version is slightly easier to use than the
comparison object version, but typically it is measureably slower.

\noindent{\bf Comparison operator version:} This version works on streams of
objects for which the operator \myverb{<} is defined. For
example, the following code would sort a stream
\noiv{instream} of \noiv{int} objects, creating the sorted
stream \noiv{outstream}.

\begin{verbatim}
AMI_STREAM<int> instream;
AMI_STREAM<int> outstream;

void f()
{
    AMI_sort(&instream, &outstream);
}
\end{verbatim}

\noindent{\bf Comparison function version:}
This version uses an explicit function to
determine the relative order of two objects in the input stream.  This
is useful in cases where we may want to sort a stream of objects in
several different ways.  For example, the following code sorts a
stream of complex numbers in two ways, by their real parts and by
their imaginary parts.

\begin{verbatim}
class complex {
public:
    complex(double real_part, imaginary_part);
    double re(void);
    double im(void);
    ...
};

int compare_re(const complex &c1, const complex &c2)
{
    return (c1.re() < c2.re()) ? -1 :
           ((c1.re() > c2.re()) ? 1 : 0);
}

int compare_im(const complex &c1, const complex &c2)
{
    return (c1.im() < c2.im()) ? -1 :
           ((c1.im() > c2.im()) ? 1 : 0);
}

AMI_STREAM<complex> instream;
AMI_STREAM<complex> outstream_re;
AMI_STREAM<complex> outstream_im;

void f()
{
    AMI_sort(&instream, &outstream_re, compare_re);
    AMI_sort(&instream, &outstream_im, compare_im);
}
\end{verbatim}

\noindent{\bf Comparison object version:} 
This version of \myverb{AMI\_sort()} is similar to the
comparison function version, except that the comparison
function is now a method of a user-defined comparison class. This polymorph of \myverb{AMI\_sort} expects an object
as its third argument. This object must have a public member
function named \myverb{compare}, whose calling sequence and
functionality is the same as for a comparison function (as
described above). The complex number example might be solved
using the comparison class version of \myverb{AMI\_sort} as
follows: \comment{LA: Check that this is correct.}

\begin{verbatim}
class compare_re_class {
public:
    int compare ( const complex &c1, const complex &c2 ) {
        return (c1.re() < c2.re()) ? -1 :
               ((c1.re() > c2.re()) ? 1 : 0);
    };
};

class compare_im_class {
public:
    int compare ( const complex &c1, const complex &c2 ) {
        return (c1.im() < c2.im()) ? -1 :
               ((c1.im() > c2.im()) ? 1 : 0);
    };
};

AMI_STREAM<complex> instream;
AMI_STREAM<complex> outstream_re;
AMI_STREAM<complex> outstream_im;

compare_re_class compare_re
compare_im_class compare_im

void f()
{
    AMI_sort(&instream, &outstream_re, &compare_re);
    AMI_sort(&instream, &outstream_im, &compare_im);
}
\end{verbatim}

%\comment{LA: We need to make the function object change!}
% \subsubsection{Optimized Sort Functions}

% Version \version~of TPIE also contains alpha versions of a new improved
% sorting function\\ %
% \myverb{AMI\_optimized\_sort()} which has three polymorphs. It is planned that
% after thorough testing this function will be the standard \myverb{AMI\_sort()}
% function. Section~\ref{sec:ref-imp-ami-sort} provide more details with
% regards to the difference in the implementation details between
% \myverb{AMI\_optimized\_sort()} and \myverb{AMI\_sort()}.

% The first two polymorphs of \myverb{AMI\_optimized\_sort()} are identical to
% the first two \myverb{AMI\_sort()} polymorphs, which relies on the \myverb{<}
% operator and a comparison function, respectively.\comment{LA: We need to
% add a comparator class polymorph also (when we do the function object
% stuff). Doing so will also make it possible to clean up the
% ami\_merge\_optimized.h code - right now there is two full copies of the
% code.} The third polymorph is based on the assumption that the objects in
% the input stream is to be sorted according to one of their fields (the
% \myverb{key} field), and that the class of this field have a well-defined
% (possibly via overloading) \myverb{<} operator. For example, consider the
% class \myverb{rectangle} below meant for axis parallel rectangles:

\subsubsection{AMI\_ptr\_sort()}

The \myverb{AMI\_ptr\_sort} variant of merge sort in TPIE
keeps only a pointer to each record in the heap used to
perform merging of runs. Similar to \myverb{AMI\_sort}
above, it offers comparison
operator, comparison function, and comparison class
polymorphs. The syntax is identical to that illustrated in
the \myverb{AMI\_sort} examples; simply replace
\myverb{AMI\_sort} by \myverb{AMI\_ptr\_sort}.

\subsubsection{AMI\_key\_sort()}

The \myverb{AMI\_key\_sort} variant of TPIE merge sort keeps
the key field(s) plus a pointer to the corresponding record
in an internal heap during the merging phase of merge sort.
It requires a sort management object with member functions
\myverb{compare} and \myverb{copy}. The usage of
\myverb{AMI\_key\_sort()} is illustrated by the following
example:


Consider the class \myverb{rectangle} below, meant to
describe axis-parallel rectangles,

\begin{verbatim}}
class rectangle{
double northEast_x;
double northEast_y;
double southWest_x;
double southWest_y;
char   long_text_description[200];
}
\end{verbatim}

\noindent
and suppose that we want to sort a stream of rectangles in
descending order according to their \myverb{southWest\_y}
coordinate. The user-written sort management object
\myverb{smo} below contains a member function \myverb{copy}
for copying the desired key field from a record (whose
address will be provided by TPIE) to a location in the heap
(determined by TPIE). 

\begin{verbatim}
// Here is the definition of the sort management class
class SortManager {
private:
    int result;
public:
   inline int compare (const double & k1, const double & k2) {
      return ((k1 < k2)? -1 : (k1 > k2) ? 1 : 0);
   }
   inline void copy (double *key, const rectangle &record) {
      *key = record.southwest_y;
   }
};

// create a sort management object
SortManager <rectangle,double> smo;
\end{verbatim}
 
Assuming that the size of each \myverb{double} is 8 bytes,
we can sort the stream as follows:
 
\begin{verbatim}
AMI_STREAM<rectangle> instream;
AMI_STREAM<rectangle> outstream;
double dummyKey;

void f()
{
    AMI_key_sort(&instream, &outstream, dummyKey, &smo );
}
\end{verbatim}

The third argument of \myverb{AMI\_key\_sort()} is a a
dummy argument having the same type as the key field, and
the fourth argument is the sort management
object.\comment{LA: Maybe we should add something about this
   being a C++ requirement?}


\index{sorting!merge|)}

\index{sorting!comparison|)}

\subsection{Key Bucket Sorting}
\plabel{sec:tut-kb-sorting}

%\index{sorting!key bucket|(}

\tobewritten


\section{Permutation}\plabel{sec:tut-permutation}

\subsection{General Permutation}

Permutation is a basic building block in many I/O
algorithms. Routing a general permutation in the I/O model
is asymptotically as complex as
sorting~\cite{aggarwal:input}, though for some important
classes of permutations, such as BMMC permutations (See
Section~\ref{sec:tut-bit-permuting}) faster algorithms are
possible~\cite{cormen:fast}. In this section, we discuss
\myverb{AMI\_general\_permute()}, which routes arbitrary
permutations, but always takes as long as sorting,
regardless of whether the particular permutation can be done
more quickly or not.

General permutations are routed using the function
\myverb{AMI\_general\_permute()}.  Like other AMI functions,
\myverb{AMI\_general\_permute()} relies on an operation management
object\index{operation management object} to determine its precise
behavior.  Unlike functions covered up to now, however, the type of
the operation management object\index{operation management object}
need not depend on the type of object in the stream being permuted.

A general permutation management object must provide two member
functions, \myverb{initialize()} and \myverb{destination()}.
\myverb{initialize()} is called to inform the general permutation object
of the length of the stream to be permuted.  \myverb{destination()} is
then called repeatedly to determine the destination for each object in
the stream based on it's initial position.

Here is an example of using general permutation to reverse the order
of the items in a stream.

\begin{verbatim}
class reverse_order : public AMI_gen_perm_object {
private:
    off_t total_size;
public:
    AMI_error initialize(off_t ts) { 
        total_size = ts; 
        return AMI_ERROR_NO_ERROR;
    };
    off_t destination(off_t source) {
        return total_size - 1 - source;
    };
};

AMI_STREAM<int> amis0, amis1;    

void f()
{
    reverse_order ro;

    AMI_general_permute(&amis0, &amis1, (AMI_gen_perm_object *)&ro);
}
\end{verbatim}


\subsection{Bit Permutation}
\plabel{sec:tut-bit-permuting}

\comment{LA: Do we really want this in the tutorial?}

Bit permuting is a permutation technique in which the destination address
of a given item is computed by manipulating the bits of its source address.
The particular class of bit permutations that TPIE supports is the set of
bit matrix multiply complement (BMMC) permutations.  These permutations are
defined on sets of objects whose size is a power of 2.

Suppose we have an input consisting of $N = 2^n$ objects.  A BMMC
permutation on the input is defined by a nonsingular $n \times n$ bit
matrix $A$ and an $n$ element column vector $c$ of bits.  Source and
destination addresses are interpreted as column vectors of bits, with
the low order bit of the address at the top. The destination address
$x'$ corresponding to a given source address $x$ is computed as
$$x' = Ax + c$$
where addition and multiplication of matrix
elements is done over GF(2)\comment{DH: we should spell out
   what GF(2) is.}. For a detailed description of BMMC
permutations, see~\cite{cormen:integrate-tr}.

Routing BMMC permutations in TPIE is done using the
\myverb{AMI\_BMMC\_permute()} entry point\comment{LA: Is it really
implemented?}, which takes an input stream, and output stream, and a
pointer to a bit permutation management object. In the following example,
we route a permutation that simply reverses the order of the source address
bits to produce the destination address.

First, we construct the matrices the permutation will use.
\index{bit_matrix@{\tt bit\_matrix}}
\begin{verbatim}
    bit_matrix A(n,n);
    bit_matrix c(n,1);

    {
        unsigned int ii,jj;

        for (ii = n; ii--; ) {
            c[ii][0] = 0;
            for (jj = n; jj--; ) {
                A[n-1-ii][jj] = (ii == jj);
            }
        }
    }
\end{verbatim}
Now we simply construct a permutation management object from the
matrices and perform the permutation.
\begin{verbatim}
    AMI_bit_perm_object bpo(A,c);
    
    ae = AMI_BMMC_permute(&amis0, &amis1, (AMI_bit_perm_object *)&bpo);
\end{verbatim}

\section{Distribution Sweeping} \plabel{sec:tut-distsweep}
\index{Distribution sweeping}
\comment{LA: Get sweeping under distribution in the index}

\tobewritten

\section{Matrix Operations}
\plabel{sec:tut-matrix}

\comment{LA: Read through this and check code.}

\index{matrices|(}

In addition to streams, which are linearly ordered collections of objects,
the AMI provides a mechanism for storing large matrices in external memory.
Matrices are a subclass of streams, and can thus be used with any of the
stream operations discussed above.  When a matrix is treated as a stream
its elements appear in row major order.  In addition to stream operations,
matrices support three simple arithmetic operations, addition, subtraction,
and multiplication.

It is assumed that the class \myverb{T} of the elements in a matrix forms a
quasiring with the operators \myverb{+} and \myverb{*}.  Furthermore, the
object \myverb{T((int)0)} is assumed to be an identity for \myverb{+}.  At the
moment, it is not assumed that the operator
\myverb{-} is an inverse of \myverb{+}, and therefore no reduced
complexity matrix multiplication algorithms analogous to Strassen's
algorithm are used.

TPIE provides support for both dense and sparse matrices.

\subsection{Dense Matrix Operations}
\plabel{sec:tut-dense-mat}

\index{matrices!dense|(}

Dense matrices are implemented by the templated class
\myverb{AMI\_matrix},\index{AMI_matrix@{\tt AMI\_matrix}}
which is a subclass of
\myverb{AMI\_STREAM}.\index{AMI_STREAM@{\tt AMI\_STREAM}}
Dense matrices can be initialized or ``filled'' using
\myverb{AMI\_scan()}, though typically they are filled using
the function \myverb{AMI\_matrix\_fill()}.
\myverb{AMI\_matrix\_fill()} wuses a scan management object
whose member function \myverb{element} is given the row and
column of each element of the matrix and must return the
value to be inserted at that position of the matrix. In the
following example, we create a 1000 by 1000 upper triangular
matrix of ones and zeroes:

\begin{verbatim}
template<class T>
class fill_upper_tri : public AMI_matrix_filler<T> {
    AMI_err initialize(unsigned int rows, unsigned int cols)
    {
        return AMI_ERROR_NO_ERROR;
    };
    T element(unsigned int row, unsigned int col)
    {
        return (row <= col) ? T(1) : T(0);
    };
};

AMI_matrix m(1000, 1000);

void f()
{
    fill_upper_tri<double> fut;

    AMI_matrix_fill(&em, (AMI_matrix_filler<T> *)&fut);
}
\end{verbatim}

Arithmetic on dense matrices is performed in a straightforward way
using the functions \myverb{AMI\_matrix\_add()},
\myverb{AMI\_matrix\_subtract()}, and \myverb{AMI\_matrix\_multiply()}, as is
the following example:

\begin{verbatim}
AMI_matrix m0(1000, 500), m1(500, 2000), m2(1000, 2000);
AMI_matrix m3(1000, 500), m4(1000, 500);

void f()
{
    // Add m3 to m4 and put the result in m0.
    AMI_matrix_add(em3, em4, em0);
   
    // Multiply m0 by em1 to get m2.
    AMI_matrix_mult(em0, em1, em2);

    // Subtract m4 from m3 and put the result in m0.
    AMI_matrix_subtract(em3, em4, em0);        
}
\end{verbatim}

\index{matrices!dense|)}

\subsection{Sparse Matrix Operations}
\plabel{sec:tut-sparse-mat}

\index{matrices!sparse|(}
\index{matrices!sparse|)}

\tobewritten


\subsection{Elementwise Arithmetic}
\plabel{sec:tut-elementwise}

\index{arithmetic!elementwise|see{elementwise arithmetic}}
\index{elementwise arithmetic|(} 
The functions \myverb{AMI\_matrix\_add()}
and \myverb{AMI\_matrix\_subtract()} defined in
Section~\ref{sec:tut-dense-mat} perform elementwise arithmetic on
matrices.  At times, we might also wish to perform elementwise
multiplication or division, or perform a scalar arithmetic operation
on all elements of a matrix.  TPIE provides mechanisms for doing this
not only on matrices, but on arbitrary streams, so long as they are of
objects for which the appropriate arithmetic operators (i.e. {\tt +},
{\tt -}, {\tt *}, {\tt /}) are defined.

Elementwise arithmetic is done with scan management objects
\index{operation management objects!scan} of the classes
\myverb{AMI\_scan\_add}, \myverb{AMI\_scan\_sub}, \myverb{AMI\_scan\_mult} and
\myverb{AMI\_scan\_div}.  Here is an example that performs
elementwise division on the elements of two streams.

\begin{verbatim}
#include <ami_stream_arith.h>

void foo()
{
    AMI_STREAM<int> amis0;
    AMI_STREAM<int> amis1;
    AMI_STREAM<int> amis2;

    AMI_scan_div<int> sd;

    // Divide each element of amis0 by the corresponding element of
    // amis1 and put the result in amis2.
    AMI_scan(&amis0, &amis1, &sd, &amis2);
}
\end{verbatim}
\index{elementwise arithmetic|)}

\index{matrices|)}


\section{External Stack}
\plabel{sec:tut-stack}

\index{External Stack}

\comment{LA: put stack, external in index}

\tobewritten

\section{Compiling and Executing a TPIE Program}
\plabel{sec:tut-compiling}

The fragments of code presented in this tutorial are designed for
instructive purposes  but they are incomplete. In order to
successfully compile, link, and run a complete TPIE application, some
additional code and configuration is needed. The configuration and
compilation of a TPIE program is discussed below. The recommended way for a
novice TPIE programmer to learn how to write a complete TPIE application is
to go through the sample program of Chapter~\ref{ch:samplepgmr} or to look
at the source code provided in the \myverb{test} directory.

The main steps involved in setting up and running a TPIE
program are as follows:\comment{DH: This mixes apples and
   oranges. Should rewrite with more focus, e.g compiling a
   TPIE Hello World program?}

\begin{enumerate}
    
    \item Various behaviors of TPIE at run time can be
    controlled by compile-time variables.  These variables
    are defined in the file \myverb{app\_config.h}
    \index{app_config@{\tt app\_config.h}} which is included
    at the beginning of a TPIE program before including any
    TPIE headers. The test application code\index{test
       applications} distributed with TPIE contains such a
    file (\myverb{/test/app\_config.h}). See
    Section~\ref{sec:tuning} for a discussion of these
    options and of how they should be set on a given
    hardware platform for best performance.
    
    \item TPIE's templated classes and functions are
    included by including the header file \myverb{ami.h}
    from the \myverb{include} directory. Normally, this
    directory is indicated via the \myverb{-I} argument to
    the compiler.
    
    \item The following statements are used to indicate that
    the TPIE memory manager \myverb{MM\_manager} should
    restrict the internal memory that it uses (to the value
    of \myverb{mm\_size} in this case).

\begin{verbatim}
   MM_manager.enforce_memory_limit ();
   MM_manager.set_memory_limit (mm_size);
\end{verbatim}
    
    Calling the \myverb{MM\_manager} member function
    \myverb{enforce\_memory\_limit ()} indicates that the
    program should abort if the allocated internal memory
    exceeds a specified amount.\comment{LA: Something about
       how TPIE counts memory?} This amount is set by the
    member function \myverb{set\_memory\_limit (mm\_size)}.
    Normally, this amount is the amount of physical main
    memory minus the main memory used by the operating
    system and other programs running on the machine. If
    \myverb{MM\_manager.ignore\_memory\_limit ()} is called,
    the application will run with virtual memory like an
    ordinary non-TPIE application.
    
    \item If a TPIE program file \myverb{foo.cpp} exists in
    the TPIE base directory it can be compiled with the
    following command:

\begin{verbatim}
g++ foo.cpp -Iinclude/ -Llib/ -ltpie -o foo
\end{verbatim}
    
    Users interested in setting up a \myverb{Makefile} for
    the compiling task can look at a sample
    \myverb{Makefile} in the \myverb{test} subdirectory.
\end{enumerate}


%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
