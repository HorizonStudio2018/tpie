%%
%% $Id: implementation.tex,v 1.9 1999-11-17 20:55:17 tavi Exp $
%%
\chapter{The Implementation of TPIE}
\label{cha:implementation}

%This chapter discusses the implementation of TPIE.
%It is primarily targeted at those who might wish to port TPIE to
%additional platforms or implement similar systems.

\section{The Structure of TPIE}
\index{structure!of TPIE} \index{components!of TPIE} TPIE
has three main components, the Access Method Interface
(AMI)\index{access method interface}, a Block Transfer
Engine (BTE)\index{block transfer engine} component, and a
Memory Manager (MM)\index{memory manager} component.
Various Block Transfer Engines (BTEs) can be chosen for
handling disk block transfers, perhaps more than one in a
single application.  The MM component provides low level
memory management services such as allocating, deallocating,
and accounting of internal memory. The AMI works on top of
the Memory Manager and one or more BTEs to provide a uniform
interface for application programs. Applications that use
this interface are portable across hardware platforms, since
they never have to deal with the underlying details of how
I/O is performed on a particular machine. This Chapter
describes the design decisions, algorithms, and
implementation decisions that were used to build the MM, BTE
and AMI components of TPIE. The Reference Section of this
manual contains a description of the AMI and Memory Manager
entry points that an application programmer might normally
use. Typically, an application programmer will not request
services from a BTE directly. For this reason, the BTE
services are not presented in the Reference Section of this
manual, but are presented here for those readers who wish to
understand the implementation details of TPIE.


%Although the BTE runs on a single processor, it can support concurrent
%access to multiple disks\index{parallel disks}, allocating and managing
%buffer space for all of them concurrently.

The MM\index{memory manager} manages random access memory on behalf of
TPIE.
%It is the most architecture-dependent component of the
%system. 
Currently, TPIE is distributed with an MM designed for a single processor, or
multiprocessor system with a single global address space. This MM is
relatively simple; its task is to allocate and manage the physical memory
used by the BTE component. 

%On a distributed memory system, the MM will have the
%additional task of coordinating communication between processors and memory
%modules in order to support the primitives that the AMI provides.

The AMI\index{access method interface} is an interface layer between the BTE and user
level processes.  It implements fundamental access methods, such as
scanning, permutation routing, merging, and distribution. It also provides
a consistent, object-oriented interface to application programs.
%The details of how these access methods are implemented depends on the
%hardware on which the system is running.  For example, recursive
%distribution will be done somewhat differently on a parallel disk machine
%than on a single disk machine. The AMI abstracts this fact away, allowing
%an application program that calls a function such as
%\myverb{AMI\_partition\_and\_merge()}\index{AMI\_partition\_and\_merge@{\tt
%AMI\\_partition\\_and\_merge}} to work correctly regardless of the underlying
%I/O system.
The key to keeping the AMI simple and flexible is the fact that its
user accessible functions serve more as templates for computation than
as actual problem solving functions.  The details of how a computation
proceeds within the template is up to the application programmer, who
is responsible for providing the functions that the template applies
to data.

\section{The Block Transfer Engine (BTE)}
\label{sec:ref-bte}
\index{block transfer engine|(}
\index{BTE|see{block transfer engine}}

\tobeextended 

The BTE component is intended to bridge the gap between the
I/O hardware and the rest of the system. It is the layer
that is ultimately responsible for moving blocks of data
from physical disk devices to main memory and back. It works
alongside the traditional buffer cache\index{buffer cache}
in a UNIX system.  Unlike the buffer cache, which must
support concurrent access to files from multiple address
spaces, the BTE is specifically designed to support high
throughput processing of data from secondary memory through
a single, user level address space.  In order to efficiently
support the merging, distribution, and scanning paradigms,
the several BTEs provides stream-oriented input and output
of data blocks.  To further improve performance, some BTE
implementations move data from disk directly into user space
rather than using a kernel-level 
buffer cache\index{buffer cache}. 
 This saves both main memory space and copying
time. In the future, TPIE will also provide a BTE
implementation with support for random-access to disk
blocks. Such functionality is useful when implementing
external data structures (indexes).  Currently, all TPIE
BTEs are designed for processing streams on a single disk.
Planned BTE implementations will be responsible for
maintaining the integrity of streams striped across multiple
disks attached to a single CPU.

\comment{LA: This whole section needs an overhaul - discuss
   implementation!}
%We hope that in most cases it will be possible for the BTE to work with
%device drivers provided by the machine vendor's operating system.  In some
%cases, however, new drivers may have to be written.
\begin{comment}
 The BTEs will not, however, be responsible for coordinating the
actions of multiple CPU's and the disks attached to them. In such cases, a
separate instance of a BTE will run on each such CPU, and their actions
will be coordinated by a single multi-threaded MM running at a higher
level. The reason for the functional split between the two levels is that
it will likely be advantageous to be able to use a single BTE written for a
specific piece of hardware with more than one MM, for example, one MM
written for a homogeneous environment and one for a heterogeneous
environment. 
\end{comment}

Version \version~of TPIE is distributed with three BTE implementations ; An
implementation based on the UNIX \myverb{stdio} library (\myverb{BTE\_stdio}),
one based on blocked UNIX {\tt read/write} calls \index{read write}
(\myverb{BTE\_ufs}), and one based on memory mapped I/O (\myverb{BTE\_mmap}). The
choice of BTE in a given application is controlled by macros in the
\myverb{app\_config.h} file.  The UNIX \myverb{stdio} implementation is selected
by defining \myverb{BTE\_IMP\_STDIO}, the \myverb{read/write} implementation by
defining \myverb{BTE\_IMP\_UFS}, while the memory mapped implementation is
selected by defining \myverb{BTE\_IMP\_MMB}. Multiple implementations are
allowed to coexist, with some restrictions.\comment{LA: This needs to be
extended somewhere.} The best choice of BTE for a given application is both
application and system dependent. Section~\ref{sec:choosingbte} discuss how
to chose an appropriate BTE (also refer to the more detailed descriptions
of the BTE's in the next three subsections). If none of the above macros is
defined, \myverb{BTE\_IMP\_STDIO} is defined by default and a warning is
generated at compile time.\comment{LA: Some intro about streams, files, ect
- like in AMI reference. Also something about; block access, read ahead,
double buffering, logical blocks, file pointer, stream types, persistence,
ect.?}

All BTE stream implementations inherit from class \myverb{BTE\_base\_stream}
(in file \myverb{bte\_base\_stream.h}) and must support the following abstract
member functions:\comment{LA: Some note about construction being BTE
dependent - why are they?}

\subsubsection{new\_substream}\index{new_substream()@{\tt new\_substream()}}
\index{substreams!of BTE streams}
\begin{verbatim}
    BTE_err new_substream(BTE_stream_type st, off_t sub_begin, off_t
                          sub_end, BTE_base_stream<T> **sub_stream);
\end{verbatim}
A virtual pseudo-constructor for substreams. The arguments \myverb{sub\_begin} and
\myverb{sub\_end} are object offsets.\comment{LA: Extend like in AMI
ref. Stream type?}


\subsubsection{read\_item}\index{read_item()@{\tt read\_item()}!BTE}
\begin{verbatim}
    BTE_err read_item(T **elt);
\end{verbatim}
Read the next object from the stream. If block boundaries are crossed the
read ahead mechanism\comment{LA: ?} is called.\comment{LA: Extend!}

\subsubsection{write\_item}\index{write_item()@{\tt write\_item()}!BTE}
\begin{verbatim}
    BTE_err write_item(const T &elt);
\end{verbatim}
Write the object to stream.\comment{LA: Extend!}


\subsubsection{seek}\index{seek()@{\tt seek()}!BTE}
\begin{verbatim}
    BTE_err seek(off_t offset);
\end{verbatim}
Seek to the object offset in the stream.


\subsubsection{truncate}\index{truncate()@{\tt truncate()}!BTE}
\begin{verbatim}
    BTE_err truncate(off_t offset);
\end{verbatim}
Truncate/extend the stream to the specified number of items. The file
pointer\comment{LA: ?} will be moved to the end of the stream.


\subsubsection{main\_memory\_usage}
\index{main_memory_usage()@{\tt main\_memory\_usage()}!BTE}
\begin{verbatim}
    BTE_err main_memory_usage(size_t *usage,
                              MM_stream_usage usage_type);
\end{verbatim}
Query memory usage.\comment{LA: ?}



\subsubsection{get\_status}\index{get_status()@{\tt get\_status()}}
\begin{verbatim}
    BTE_stream_status get_status(void);
\end{verbatim}
Returns the status of the stream as one
of the following:\comment{LA: Is this really used anywhere?}
\index{BTE_STREAM_STATUS_*@{\tt BTE\_STREAM\_STATUS\_*}}
\begin{itemize}
\item \myverb{BTE\_STREAM\_STATUS\_NO\_STATUS}
\item \myverb{BTE\_STREAM\_STATUS\_INVALID}
\item \myverb{BTE\_STREAM\_STATUS\_EOS\_ON\_NEXT\_CALL}
\item \myverb{BTE\_STREAM\_STATUS\_END\_OF\_STREAM}
\end{itemize}


\subsubsection{stream\_len}\index{stream_len()@{\tt stream\_len()}!BTE}
\begin{verbatim}
    off_t stream_len(void);
\end{verbatim}
Returns the current number of items in the stream.


\subsubsection{name}\index{name()@{\tt name()}!BTE}
\begin{verbatim}
    BTE_err name(char **stream_name);
\end{verbatim}
Returns the path name of the file backing the stream. The name will be
stored in newly allocated space.


\subsubsection{read\_only}\index{read_only()@{\tt read\_only()}}
\begin{verbatim}
    int read_only(void);
\end{verbatim}
Returns true if the stream is read\_only.\comment{LA: ?}

    
\subsubsection{available\_streams}
\index{available_streams()@{\tt available\_streams()}!BTE}
\begin{verbatim}
    int available_streams(void);    
\end{verbatim}
Returns the number of currently available streams.\comment{LA: Extend}

\subsubsection{chunk\_size}
\begin{verbatim}
    off_t chunk_size(void);
\end{verbatim}
%Not clear what this does...
Returns the number of elements that fit in a logical block.\comment{LA: ?}

\subsubsection{persist}\index{persistence!BTE}
\index{persist()@{\tt persist()}|see{persistence}}
\begin{verbatim}
    void persist(persistence);
\end{verbatim}
Set the persistence of the stream to one of the following:
\begin{itemize}
\item \myverb{PERSIST\_DELETE:} Delete the stream from the disk when it is
  destructed.
\item \myverb{PERSIST\_PERSISTENT:} Do not delete the stream from the disk when
  it is destructed.
%\item \myverb{PERSIST\_READ\_ONCE:} Delete each block of data from the disk as
%  it is read.
\end{itemize}

By default, all streams are deleted at destruction time
(\myverb{PERSIST\_DELETE}).

\index{BTE_stream_stdio@{\tt BTE\_stream\_stdio}|see{BTE\_stdio}}
\subsection{BTE\_stdio}\index{BTE_stdio@{\tt BTE\_stdio}|(}

\tobeextended

\myverb{BTE\_stdio} streams (defined in file \myverb{/include/bte\_stdio.h}) are
streams in a special format that are designed to be stored as ordinary
files in a UNIX file system. The read/write primitives of \myverb{BTE\_stdio}
streams are implemented using system calls \myverb{fread} and
\myverb{fwrite}. The underlying operating system blocking and prefetching
assure that stream accesses are done in blocks and prefetching is therefore
automatic and invisible to the TPIE developer. Note that this means that a
(OS) kernel call is incurred every time a stream object is
accessed, and that every object passes through kernel level buffer space on
its way to user space.

\comment{LA: Extend. Also something about no logical block size
concept.}

\myverb{BTE\_stdio} streams are stored as ordinary UNIX files with a 
header\index{BTE_stdio@{\tt BTE\_stdio}!header} with the following structure:

\index{BTE_stdio_header@{\tt BTE\_stdio\_header}}
\begin{verbatim}
typedef struct BTE_stdio_header_v1 { 
    unsigned int magic_number;  // Set to BTE_STDIO_HEADER_MAGIC_NUMBER
    unsigned int version;       // Should be 1 for current version.
    unsigned int length;        // # of bytes in this structure.
    unsigned int block_length;  // # of bytes in a block.
    size_t item_size;           // The size of each item in the stream.
} BTE_stdio_header;
\end{verbatim}

\myverb{BTE\_stream\_stdio} class inherits from \myverb{BTE\_base\_stream} (in file
\myverb{/include/bte\_base\_stream.h}):\index{BTE_base_stream@{\tt BTE\_base\_stream}}
\begin{verbatim}
class BTE_stream_stdio : public BTE_base_stream {
  private:
     FILE  *file;          
     BTE_stdio_header      header;
     ...
}  
\end{verbatim}

\myverb{BTE\_stream\_stdio} defines the abstract methods inherited from
\myverb{BTE\_base\_stream} presented in the previous section.\comment{LA:
Extend - discuss implementation!} In addition to these it defines its own
constructors:\index{BTE_stdio@{\tt BTE\_stdio}!constructors}

\begin{verbatim}
     BTE_stream_stdio(const char *dev_path, const BTE_stream_type st); 
     BTE_stream_stdio(const BTE_stream_type st); 
     BTE_stream_stdio(const BTE_stream_stdio<T> &s);
\end{verbatim}
\index{BTE_stdio@{\tt BTE\_stdio}|)}

\index{BTE_stream_mmb@{\tt BTE\_stream\_mmb}|see{BTE\_mmb}}
\subsection{BTE\_mmb}\comment{LA: Why not called BTE\_mmp?}\index{BTE_mmb@{\tt BTE\_mmb}|(}

\tobeextended

Just like \myverb{BTE\_stdio} streams presented in the previous section,
\myverb{BTE\_mmb} streams (defined in file \myverb{/include/bte\_mmb.h}) are
streams in a special format that are designed to be stored as ordinary
files in a UNIX file system. What distinguishes them from \myverb{BTE\_stdio}
streams is the way stream input/output is implemented. The \myverb{BTE\_mmb}
uses the memory map paradigm where a part of a file can be memory mapped
(using \myverb{mmap}) such that one can work on it as if that part of the
file were in memory. The \myverb{BTE\_mmb} primitives explicitly maintain the
currently accessed block of the file mapped into memory. When an object
outside the current block boundaries is requested, the current block is
unmapped and a new one is mapped from the source file.

The \myverb{BTE\_mmb} is not limited to mapping in blocks of size equal to the
physical block size of the OS (typically 8K bytes). Often improved
performance can be obtained by mapping blocks of much larger size (for
example 256Kbytes). This is typically due to (track) buffering and
prefetching performed in the disk controller. The (logical) block size used
by \myverb{BTE\_mmb} can be set using the macro
\myverb{BTE\_MMB\_LOGICAL\_BLOCKSIZE\_FACTOR} in the \myverb{app\_config.h}
file. However, choosing a large (logical) block size limits the amount of
main memory available for an application program and thus the (logical)
block size should be chosen very carefully in order to obtain maximal
performance.

Unlike in \myverb{BTE\_stdio}, where a function call is incurred every time a
stream object is accessed, the \myverb{BTE\_mmb} only incurs such a call on
every (logical) block. This can lead to improved performance, especially on
systems with a relatively slow CPU compared to the disk. However, while
prefetching of disk blocks is implicitly done by the operating system in
\myverb{BTE\_stdio}, \myverb{BTE\_mmb} has to implement its own prefetching
scheme. (Note on the other hand that unlike in \myverb{BTE\_stdio} objects
does not pass through the kernel level buffer space on its way to user
space). \myverb{BTE\_mmb} prefetching can be turned on by defining the macro
\myverb{BTE\_MMB\_READ\_AHEAD} in the \myverb{app\_config.h} file. If this macro is
defined, the BTE optimize for sequential read speed by reading (mapping)
blocks into main memory before the data they contain is actually
needed. Two methods of read-ahead is provided:
\begin{itemize}
\item If the \myverb{USE\_LIBAIO} macro is undefined (and
\myverb{BTE\_MMB\_READ\_AHEAD} is set), read ahead is done using \myverb{mmap}
calls.
\item If the \myverb{USE\_LIBAIO} macro is defined (and
\myverb{BTE\_MMB\_READ\_AHEAD} is set), read ahead is done using the
asynchronous I/O library. This feature requires the asynchronous I/O
library {\tt libaio}.\index{libaio library@{\tt libaio}
library.}
\end{itemize}
By default \myverb{BTE\_MMB\_READ\_AHEAD} is defined, \myverb{USE\_LIBAIO} is
not.\comment{LA: Discuss the two and how they differ.}

The \myverb{BTE\_mmb} header\index{BTE_mmb@{\tt BTE\_mmb}!header} structure is very similar to the \myverb{BTE\_stdio}
one:
\index{mmap_stream_header@{\tt mmap\_stream\_header}}
\begin{verbatim}
struct mmap_stream_header { 
  public:
    unsigned int magic_number;  // Set to MMB_HEADER_MAGIC_NUMBER
    unsigned int version;       // Should be 1 for current version.
    unsigned int length;        // # of bytes in this structure.
    off_t item_logical_eof;     // The number of items in the stream.
    size_t item_size;           // The size of each item in the stream.
    size_t block_size;          // The size of a physical block on the device
                                // where this stream resides.
    unsigned int items_per_block;
};
\end{verbatim}

\myverb{BTE\_mmb} class inherits from \myverb{BTE\_base\_stream}:\index{BTE_base_stream@{\tt BTE\_base\_stream}}
\begin{verbatim}
class BTE_stream_mmb : public BTE_base_stream {
  private:
     // descriptor of the mapped file.  
     int fd;   
     // A pointer to the mapped in header block for the stream. 
     mmap_stream_header *header;
     ...
}  
\end{verbatim}

\myverb{BTE\_stream\_mmb} defines the abstract methods inherited from
\myverb{BTE\_base\_stream} presented in a previous section.\comment{LA: Extend
- discuss implementation.} In addition to these it defines its own
constructors:\index{BTE_mmb@{\tt BTE\_mmb}!constructors}
\begin{verbatim}
  BTE_stream_mmb(const char *dev_path, BTE_stream_type st); 
  BTE_stream_mmb(BTE_stream_type st); 
  BTE_stream_mmb(BTE_stream_mmb<T> &s); 
  
  // A substream constructor.
  BTE_stream_mmb(BTE_stream_mmb *super_stream,
                 BTE_stream_type st,
                 off_t sub_begin, off_t sub_end);
\end{verbatim}\comment{LA: Why special substream constructor?}
\index{BTE_mmb@{\tt BTE\_mmb}|)}

\subsection{BTE\_UFS}\index{BTE_ufso@{\tt BTE\_ufs}|(}

\tobeextended

As in the previously described BTE stream implementations, \myverb{BTE\_ufs}
streams (defined in file \myverb{/include/bte\_ufs.h}) are essentially Unix
files that have been specially formated to facilitate TPIE-specific stream
operations. Actually, barring the value of one certain header field, the
stream format of \myverb{BTE\_ufs} streams is identical to \myverb{BTE\_mmb}
streams. \myverb{BTE\_ufs} streams differ from \myverb{BTE\_mmb} streams in the
particular system calls used to implement I/O and buffering: While
\myverb{BTE\_mmb} streams use the memory map paradigm to implement I/O,
\myverb{BTE\_ufs} streams use \myverb{read()}/\myverb{write()} calls to implement
their I/O. The motivation behind implementing \myverb{BTE\_ufs} streams is an
empirically observed inefficiency\footnote{The inefficiency can occur on
account of various reasons. On one system, \myverb{mmap()} calls were
implemented on top of \myverb{stdio} interface instead of a direct I/O
implementation, resulting in extra overhead.} of \myverb{mmap()}
implementations in some systems.\comment{LA: Say that its Solaris?} In such
situations, another stream implementation that, like \myverb{BTE\_mmb}
streams, have the potential of exploiting large sized blocks and buffers is
needed.

The \myverb{BTE\_ufs} stream implementation simulates the \myverb{BTE\_mmb}
stream implementation: Whenever the latter maps in a new block, the former
reads in a new block (via \myverb{read()}) and whenever the latter unmaps a
block, the latter attains the same result via a \myverb{write()} call. But
the \myverb{BTE\_ufs} implementation involves explicitly keeping track in the
BTE code various things which are ``under the hood'' in \myverb{mmap()}
implementations.\comment{LA: Like what?} In fact, the code in the
\myverb{BTE\_ufs} implementation can be said to amount to a (very rudimentary)
\myverb{mmap()} implementation. Like in the case of \myverb{BTE\_mmb} the
(logical) block size can be controlled using the macro
\myverb{BTE\_UFS\_LOGICAL\_BLOCKSIZE\_FACTOR}. \myverb{BTE\_ufs} also has the same
advantage as \myverb{BTE\_mmb} over \myverb{BTE\_stdio} of only incurring one
kernel call per block. However, unlike \myverb{BTE\_mmb} (but like
\myverb{BTE\_stdio}), prefetching is done implicitly by the filesystem
underlying TPIE (and objects have to pass through kernel level buffer
space)
%In fact, nowadays, in the case of sequential accesses, most filesystems
%almost surely implement readahead prefetching, which should suffice for the
%purpose of streaming operations in TPIE. (In the case of non-sequential
%acceses, the next block to be accessed is more often than not dependent on
%the processing of the contents of the current block, so prefetching is
%difficult to implement or impossible.)
In \myverb{BTE\_ufs} streams, when the asynchronous I/O library
\myverb{libaio}\index{libaio library@{\tt libaio} library.} is available,
there is a provision to do (user-level) prefetching within \myverb{BTE\_ufs}
streams but we do not recommend its use on account of the implicit
filesystem prefetching.

The \myverb{BTE\_ufs} header structure is identical to the \myverb{BTE\_mmb} one:
\index{mmap_stream_header@{\tt mmap\_stream\_header}}
\index{BTE_ufs@{\tt BTE\_ufs}!header}
\begin{verbatim}
struct mmap_stream_header { 
  public:
    unsigned int magic_number;  // Set to UFS_HEADER_MAGIC_NUMBER
    unsigned int version;       // Should be 1 for current version.
    unsigned int length;        // # of bytes in this structure.
    off_t item_logical_eof;     // The number of items in the stream.
    size_t item_size;           // The size of each item in the stream.
    size_t block_size;          // The size of a physical block on the device
                                // where this stream resides.
    unsigned int items_per_block;
};
\end{verbatim}

\myverb{BTE\_ufs} class inherits from \myverb{BTE\_base\_stream}:\comment{LA: Why
called BTE\_single\_disk and not BTE\_stream\_ufs??}
\begin{verbatim}
class BTE_single_disk : public BTE_base_stream { 
  private:
     // descriptor of the mapped file.  
     int fd;
     // A pointer to the mapped in header block for
     the stream.  mmap_stream_header *header; ...  }
\end{verbatim}

\myverb{BTE\_ufs} defines the abstract methods inherited from
\myverb{BTE\_base\_stream} presented in a previous section. In addition to
these it defines its own constructors:\index{BTE_ufs@{\tt BTE\_ufs}!constructors}
\begin{verbatim}
  BTE_single_disk(const char *dev_path, BTE_stream_type st); 
  BTE_single_disk(BTE_stream_type st); 
  BTE_single_disk(BTE_single_disk<T> &s); 
  
  // A substream constructor.
  BTE_single_disk(BTE_single_disk *super_stream,
                 BTE_stream_type st,
                 off_t sub_begin, off_t sub_end);
\end{verbatim}\comment{LA: Why a special substream constructer?}
\index{BTE_ufs@{\tt BTE\_ufs}|)}
\comment{LA: Discuss implementation!}


\section{The Memory Manager (MM)}
\label{sec:ref-mm}
\index{memory manager|(}
\index{MM|see{memory manager}}
\index{MM_manager@{\tt MM\_manager}|see{memory manager}}

The Memory Manager components of TPIE provide services related to
the management of internal memory:
\begin{itemize}
\item allocation and deallocation of (internal)
memory as requested by the \myverb{new} and \myverb{delete} operators,
\item accounting of memory usage (when required),
\item enforcing of the user-specified internal memory usage
limit (when required),
\item logging of memory allocation requests (when required).
\end{itemize}

In version \version of TPIE, the memory manager
\myverb{MM\_manager}, is built from the source files
\myverb{mm\_register.cpp}, \myverb{mm\_base.cpp},
\myverb{mm\_register.h}, and \myverb{mm\_base.h}.  The memory
manager traps memory allocation and deallocation requests in
order to monitor and enforce memory usage limits. It
provides a number of user-callable functions and services,
which are documented in Chapter \ref{cha:reference}.

\tobewritten

\comment{LA: There is some text in here that I commented out.}

%The MM is the layer of TPIE that sits between the AMI interface and the
%BTE.  Its primary role is managing main memory, including memory that
%may be distributed across multiple physical machines.  The performance
%of many of the AMI stream operations, such as sorting, permuting,
%merging, and distribution depend critically on the efficient use of
%main memory.  The first thing the MM will have to do to achieve this
%is bypass the virtual memory system provided by UNIX and related
%operating systems.  The second thing it has to do is bypass the
%traditional UNIX buffer cache and take charge of managing the blocks
%of data provided by the BTE.  In some cases, operating system kernels
%will have to be modified in order for the MM to do its job.  In modern
%micro-kernel operating systems, however, the MM may be able to operate
%entirely as a user level process.

%In multiple CPU environments, the job of the MM will be complicated by
%the need to manage multiple banks of memory.  In tightly coupled
%homogeneous parallel environments, this task is likely to be made far
%simpler by existing hardware and operating system support.  In
%distributed, and in particular in heterogeneous environments, the MM
%will have to work with various network protocols and drivers to
%accomplish its task.

%Some comments on the current simple MM that we have and some OS issues
%that come up in attempting to make it more robust.

\index{memory manager|)}


\section{The Access Method Interface (AMI)}
\index{access method interface|(}
\index{AMI|see{access method interface}}
\label{sec:ref-ami}

\tobeextended

\myverb{ami\_single.h} (\myverb{ami\_base.h})

\comment{LA: Talk about streams ect (built on top of BTE\_STREAM.)}

\comment{LA: Remember to include something about r\_only flag somewhere.}

\comment{LA: There is a lot of text in here I have commented out}

%To use TPIE, the programmer has to create, modify or delete items each of
%which belongs to a stream. From the programmer's perspective,
%computation simply requires her to \emph{choreograph the movement of
%items in various streams}: The I/O operations, the buffering required
%and memory management are performed in TPIE itself. In order to specify
%the choreography of streams, the user can make heavy use of inbuilt
%TPIE templates and functions; it is not often that the user has to write
%special-purpose custom-made TPIE functions. The reason why TPIE's unique
%approach is attractive for external memory computation is the well
%known fact that most external memory algorithms consist of sewing
%together a small number of paradigms such as \emph{scanning},
%\emph{merging}, \emph{distributing}, in a well-coordinated manner
%exploiting all available memory and I/O bandwidth. A large variety of 
%indexing data structures and methods related to those data structures 
%can be implemented using the above paradigms in conjunction with a 
%basic tree template: While indexing data structures have been
%implemented using TPIE streams, work on tree templates and related
%methods to further ease implementation of indexing data structures is
%currently ongoing.

%Each datum in TPIE is an item of a certain type.
%The programmer can access data by using the
%\emph{Access Method Interface (AMI)} to access items in 
%\myverb{AMI\_STREAM}s. Items of type T constitute an AMI\_STREAM of 
%type T. Each \myverb{AMI\_STREAM} is a wrapper around  what is known
%as a \myverb{BTE\_STREAM}, where BTE stands for \emph{block transfer
%engine.} Each \myverb{BTE\_STREAM} is a stream built on top of a Unix file, with 
%additional features such as typing,  and automatic, efficient,
%``under-the-hoods'' I/O and buffering so that the programmer does
%not bear this burden. TPIE can be configured to use one of three
%different \myverb{BTE\_STREAM} implementations: The implementations vary
%fundamentally in the way they do buffering and I/O. The implementation
%of choice depends, to some extent, on the operating system on which 
%TPIE runs. Later we describe the different BTE implementations and
%how to determine the best implementation on any given system; for now,
%we focus on the \myverb{AMI\_STREAM} interface since that is most directly
%relevant to a programmer/user.


%Note that the string \myverb{AMI\_STREAM} has
% been \myverb{#define}d to be the string \myverb{AMI\_stream\_single} in the
% header file \myverb{ami\_imps.h} to facilitate alternative implementations
%of \myverb{AMI\_STREAM} if necessary in the future.
%The member functions of the \myverb{AMI\_STREAM} class,
%templated on the type T of its items,  are defined in the file \myverb{ami\_single.h};
%some important related enumerated types that the user will be
% concerned with have been defined in \myverb{ami\_base.h}.


%An important consequence of the construction of an \myverb{AMI\_STREAM} is a
%reduction in the total amount of memory that the user has at her
%disposal since a certain amount of memory is consumed now by buffers
%dedicated to that \myverb{AMI\_STREAM} and its related data
%structures.\footnote{The total amount of memory that the user has
%available, divided by the memory consumed by every AMI\_STREAM thus
%is an upper bound on the maximum number of AMI\_STREAMs that the user
%can have.}
 
%In order to effectively utilize memory, the user needs to keep track
%of the amount of memory she has at her disposal: Sometimes, 
%when one of several algorithms may be usable to solve a given problem,
%it may be useful to choose the algorithm depending on the problem
%size and available memory size. The total amount of memory consumed
%by an \myverb{AMI\_STREAM} often plays an important role while making such 
%a choice. The memory manager \myverb{mm.h} is responsible for keeping
%track of the amount of memory avaoable to the user at any time.

%When an \myverb{AMI\_STREAM} is destroyed using a destructor, that
%amount of memory becomes is added to the available memory for the
%user. 


%Sometimes the
%items in an \myverb{AMI\_STREAM} will never be used  once the \myverb{AMI\_STREAM} is
%destructed whereas sometimes an ``idle'' \myverb{AMI\_STREAM} may be destroyed 
%to prevent it from hogging memory only to be constructed later on
%when really required. In the former case, it is desirable to 
%destroy or delete the Unix file backing the \myverb{AMI\_STREAM} to save
%disk space whereas in the latter case we need the Unix file backing
%the \myverb{AMI\_STREAM} to exist on disk even when the \myverb{AMI\_STREAM} is
%destroyed. The  \myverb{AMI\_STREAM} destructor looks at the persistence 
%flag to decide whether it need only close the backing Unix file or
%delete it from disk.


\index{access method interface|)}

\subsection{Scanning}
\index{scanning|(}
\index{scanning|)}

\tobeextended

\myverb{ami\_scan.h}

\subsection{Merging}
\index{merging|(}

\tobeextended

\myverb{ami\_merge\_base.h}

%\subsubsection{Merge Management Objects}
%
%Merge management objects based on the super class \myverb{AMI\_merge\_base} 
%defined in the file \myverb{ami\_merge.h} can be used conveniently by
%appropriately defining the member functions of the class.

\subsubsection{Merging using Merge Management Objects}

\tobeextended

\myverb{ami\_merge.h}\comment{LA: Remember something about ami\_merge really
called ami\_single\_merge.}

\subsubsection{Merging without Merge Management Objects}

\tobeextended

The \myverb{AMI\_merge()} polymorphs (defined in file
\myverb{ami\_optimized\_merge.h}) that works without a merge management object
all perform standard (total order/comparison based) merging. The
elimination of the merge management object object results in one less level
of function calls and thus in improved efficiency over a similar comparison
based merging based on a merge management object. The merge is controlled
by a very simple priority queue implementation (in file \myverb{mergeheap.h})
which exploits the fact that its used to perform comparison based merging
(\myverb{delete-min} and \myverb{insert} is always performed together). Also
this improves efficiency. In the polymorph of \myverb{AMI\_merge()} which
relies on the objects having a special key field, the heap only store the
key and not the entire object. When the object size is large compared to
key size, this often leads to further performance improvement.\comment{LA:
Extend this stuff so it becomes readable}

\subsubsection{Partition and Merge}

\tobeextended

\myverb{AMI\_partition\_and\_merge()} repeatedly merges together the maximum
possible number of sub-streams using \myverb{AMI\_merge()}. An important point
is that the substreams input to \myverb{AMI\_merge()} during the execution of
\myverb{AMI\_partition\_and\_merge()} all originate from the same underlying
parent \myverb{AMI\_STREAM}; thus filesystem accesses are inherently
non-sequential. Throughout the execution of
\myverb{AMI\_partition\_and\_merge()}, there are only two active
\myverb{AMI\_STREAM}s at any time: One which stores the substreams being
merged at that stage and one which stores the substreams output by that
stage.\comment{LA: Extend this stuff so that it becomes readable!}


\subsection{Comparison Sorting}
\label{sec:ref-imp-ami-sort}
\index{sorting!comparison|(}

\tobeextended

The comparison sort polymorphs \myverb{AMI\_sort()} are defined in the file
\myverb{ami\_sort\_single.h}. They are implemented using
\myverb{AMI\_partition\_and\_merge()} and a merge management object. The member
functions \myverb{main\_mem\_operate()}, \myverb{initialize()}, and
\myverb{operate()} of the merge management object are defined to reflect
comparison sorting. \myverb{main\_mem\_operate()} is simply a sorting algorithm
based on an implementation of quicksort (in file
\myverb{quicksort.h}). \myverb{operate()} is implemented in the straightforward
way using a standard priority queue implementation (in file
\myverb{pqueue\_heap.h}). \myverb{initialize()} just initializes this
queue.\comment{LA: extend/rewrite?}

As the \myverb{AMI\_sort()} polymorphs are based on
\myverb{AMI\_partition\_and\_merge()} which in turn are based on
\myverb{AMI\_merge()} and a merge management object, the
\myverb{AMI\_optimized\_sort()} polymorphs are based on the \myverb{AMI\_merge()}
polymorphs that do not use a merge management object. Thus
\myverb{AMI\_optimized\_sort()} benefits from the efficiency improvement
obtained in \myverb{AMI\_optimized\_merge()} relative to
\myverb{AMI\_merge()}. \myverb{AMI\_optimized\_sort()} is a merge sort implemented
along the lines of \myverb{AMI\_partition\_and\_merge()} (in fact the
implementation of \myverb{AMI\_optimized\_sort()} really is an
\myverb{AMI\_partition\_and\_merge()} polymorphs defined in the file
\myverb{ami\_optimized\_merge.h}). One main difference between the
\myverb{AMI\_sort()} and \myverb{AMI\_optimized\_sort()} implementations is in the
way they store the (sub-) streams to be merged after the initial in-memory
sorting is performed. The number, say $R$, of streams being merged together
at any time is the maximum possible for the amount of memory available. In
contrast to the \myverb{AMI\_sort()} implementations which only have two
streams active at any time with the $R$ substreams stored 'inside' them,
the \myverb{AMI\_optimized\_sort()} implementations have $R$ streams active at
any time: While the $R$ sub-streams sent for merging by the
\myverb{AMI\_sort()} function all have the same parent stream, the $R$
sub-streams sent for merging by the \myverb{AMI\_optimized\_sort()}
implementations all reside in different parent streams. Thus, each stream
(file) involved is accessed in a sequential manner. This can greatly
improve performance.

On final difference between the two sorting algorithm implementation is
that during the initial main memory sort the \myverb{AMI\_optimized\_sort()}
polymorph which relies on the objects having a special key field first
extracts the keys from the objects and sorts them to obtain the order of
the objects in memory. The full objects are then permuted to reflect this
order. Again this result in improved efficiency if the keys are much
smaller than the objects.\comment{LA: This section really needs to be
rewritten.}

\comment{LA: Knuth forecasting stuff?}

\index{sorting!comparison|)}


\subsection{Distribution}
\label{sec:ref-imp-ami-distribution}

\tobewritten

\index{Distribution}

\subsection{Key Bucket Sorting}
\label{sec:ref-imp-ami-kb-sort}

\tobewritten

\index{sorting!key bucket|(}
\index{sorting!key bucket|)}

\subsection{General Permuting}
\label{sec:ref-imp-ami-gp}

\tobewritten

\index{permutation!general|(}
\index{permutation!general|)}

\subsection{Bit Permuting}
\label{sec:ref-imp-ami-bp}

\tobewritten

\index{permutation!bit|(}
\index{permutation!bit|)}

\subsection{Dense Matrices}
\label{sec:ref-imp-ami-matrix}

\tobewritten

\index{matrices!dense|(}
\index{matrices!dense|)}

\subsection{Sparse Matrices}
\label{sec:ref-imp-ami-sm}

\tobewritten

\index{matrices!sparse|(}
\index{matrices!sparse|)}

\subsection{Stacks}
\label{sec:ref-imp-ami-stack}

\tobewritten

\index{stacks|(}
\index{stacks|)}

\subsection{Elementwise Arithmetic}
\label{sec:ref-imp-ami-arith}

\tobewritten

\index{elementwise arithmetic|(}
\index{elementwise arithmetic|)}

%%% Local Variables: 
%%% mode: latex
%%% TeX-master: t
%%% End: 
